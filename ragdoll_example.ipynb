{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGdoll example\n",
    "\n",
    "@untrueaxioms\n",
    "\n",
    "<img src='img/github-header-image.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ragdoll.config.Config object at 0x0000024589C8CB90>\n",
      "Running in a Jupyter Notebook or JupyterLab environment.\n"
     ]
    }
   ],
   "source": [
    "from ragdoll.helpers import is_notebook\n",
    "from ragdoll.index import RagdollIndex\n",
    "\n",
    "index= RagdollIndex({'enable_logging':True})\n",
    "\n",
    "print(index.get_config())\n",
    "check_notebook = is_notebook(print_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RagdollIndex class handles all the tasks outlined in the diagram below (see more at langchain's documentation)\n",
    "\n",
    "<img src='img/load_split_embed_store.png' height='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload():\n",
    "    import importlib\n",
    "\n",
    "    ragdoll_index_module = importlib.import_module(\"ragdoll.index\")  # Assuming the module exists\n",
    "    importlib.reload(ragdoll_index_module)\n",
    "    index= RagdollIndex({'enable_logging':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set question for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"tell me more about langchain\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['langchain features and benefits', 'langchain reviews and testimonials']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_queries = index.get_suggested_search_terms(question)\n",
    "search_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=index.get_search_results(search_queries)\n",
    "#can also access this via index.search_results or get the urls only with index.url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  * https://www.marktechpost.com/2023/12/14/what-is-langchain-use-cases-and-benefits/\n",
      "  * https://lakefs.io/blog/what-is-langchain-ml-architecture/\n",
      "  * https://logankilpatrick.medium.com/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28\n",
      "  * https://news.ycombinator.com/item?id=36645575\n",
      "  * https://www.reddit.com/r/aipromptprogramming/comments/13f8gjr/review_langchain_vs_huggingfaces_new_agent_system/\n",
      "  * https://github.com/hwchase17/langchain/issues/4772\n"
     ]
    }
   ],
   "source": [
    "urllist = f\"\".join(f\"\\n  * {d['href']}\" for i, d in enumerate(results))\n",
    "print(urllist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "extracted 6 sites\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.marktechpost.com/2023/12/14/what-is-langchain-use-cases-and-benefits/ \n",
      "\n",
      " What is LangChain? Use Cases and Benefits\n",
      "LangChain is an artificial intelligence framework designed for programmers to develop applications using large language models. It allows you to facilitate the creation of applications that consist of two key features:\n",
      "1. Context-Awareness: LangChain enables applications to be context-aware by establishing connections between a language model and various context sources. These sources may include prompt instructions, few-shot examples, or other content t\n"
     ]
    }
   ],
   "source": [
    "documents = index.get_scraped_content()\n",
    "print(\"-\" * 100)\n",
    "print(f\"extracted {len(documents)} sites\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(documents[0].metadata['source'],'\\n\\n',documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Document Splitting is required to split documents into smaller chunks. Document splitting happens after we load data into standardised document format but before it goes into the vector store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default RecursiveSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "How the text is split: by list of characters.\n",
    "How the chunk size is measured: by number of characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "extracted 97 documents from 6 documents\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "split_docs = index.get_split_documents(documents)\n",
    "print(\"-\" * 100)\n",
    "print(f\"extracted {len(split_docs)} documents from {len(documents)} documents\")\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline \n",
    "\n",
    "we can also run all in one like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "extracted 97 documents from 6 documents\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "split_docs = index.run_index_pipeline(question)\n",
    "print(\"-\" * 100)\n",
    "print(f\"extracted {len(split_docs)} documents from {len(documents)} documents\")\n",
    "print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "The retrieval class handles the following activities:\n",
    "\n",
    "\n",
    "<img src='img/retrieve_augment_prompt.png' height='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed and Store\n",
    "\n",
    "Let’s start by initializing a simple vector store retriever and storing our docs (in chunks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragdoll.retriever import RagdollRetriever\n",
    "\n",
    "ragdoll = RagdollRetriever(config={'enable_logging':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic retrieval\n",
    "\n",
    "let's create a vector store from the split_docs and then query it using similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this code if you want to test with a local doc.\n",
    "\n",
    "# from langchain.docstore.document import Document\n",
    "\n",
    "# split_docs = [\n",
    "#     Document(page_content=\"LangChain is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\", metadata={'source': 'wikipedia'})\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ragdoll.get_db(split_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "The similarity store returned 4 relevant documents\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "Source: https://www.marktechpost.com/2023/12/14/what-is-langchain-use-cases-and-benefits/\n",
      "Title: What is LangChain? Use Cases and Benefits - MarkTechPost\n",
      "Content: What is LangChain? Use Cases and Benefits\n",
      "LangChain is an artificial intelligence framework designed for programmers to develop applications using large language models. It allows you to facilitate the creation of applications that consist of two key features:\n",
      "1. Context-Awareness: LangChain enables applications to be context-aware by \n"
     ]
    }
   ],
   "source": [
    "from ragdoll.helpers import pretty_print_docs\n",
    "\n",
    "simdocs = db.similarity_search('tell me about langchain')\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(f\"The similarity store returned {len(simdocs)} relevant documents. below is a snippet:\")\n",
    "print(\"-\" * 100, \"\\n\\n\")\n",
    "print(pretty_print_docs(simdocs, for_llm=False)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now utilise a langchain retriever based on our selected vector db. A langchain retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ragdoll.get_retriever() \n",
    "# we can do this because the vector db has already been created\n",
    "#if we havent run get_db yet, we can simply create the retriever with ragdoll.get_retriever(documents=split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "The retriever returned 4 relevant documents. below is a snippet:\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "Source: https://www.marktechpost.com/2023/12/14/what-is-langchain-use-cases-and-benefits/\n",
      "Title: What is LangChain? Use Cases and Benefits - MarkTechPost\n",
      "Content: What is LangChain? Use Cases and Benefits\n",
      "LangChain is an artificial intelligence framework designed for programmers to develop applications using large language models. It allows you to facilitate the creation of applications that consist of two key features:\n",
      "1. Context-Awareness: LangChain enables applications to be context-aware by \n"
     ]
    }
   ],
   "source": [
    "simdocs = retriever.get_relevant_documents(\"what is langchain\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"The retriever returned {len(simdocs)} relevant documents. below is a snippet:\")\n",
    "print(\"-\" * 100, \"\\n\\n\")\n",
    "print(pretty_print_docs(simdocs, for_llm=False)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on “distance”. But, retrieval may produce different results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.\n",
    "\n",
    "The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the MultiQueryRetriever might be able to overcome some of the limitations of the distance-based retrieval and get a richer set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
