{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGdoll example\n",
    "\n",
    "@untrueaxioms\n",
    "\n",
    "<img src='img/github-header-image.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enable_logging': True, 'max_search_results_per_query': 5, 'alternative_query_term_count': 5, 'max_workers': 3, 'embeddings': 'OpenAIEmbeddings', 'vector_store': 'FAISS'}\n",
      "Running in a Jupyter Notebook or JupyterLab environment.\n"
     ]
    }
   ],
   "source": [
    "from ragdoll.helpers import is_notebook\n",
    "from ragdoll.index import RagdollIndex\n",
    "\n",
    "index= RagdollIndex({'enable_logging':True})\n",
    "\n",
    "print(index.get_config())\n",
    "check_notebook = is_notebook(print_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RagdollIndex class handles all the tasks outlined in the diagram below (see more at langchain's documentation)\n",
    "\n",
    "<img src='img/load_split_embed_store.png' height='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload():\n",
    "    import importlib\n",
    "\n",
    "    ragdoll_index_module = importlib.import_module(\"ragdoll.index\")  # Assuming the module exists\n",
    "    importlib.reload(ragdoll_index_module)\n",
    "    index= RagdollIndex({'enable_logging':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set question for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"tell me more about langchain\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is Langchain and how does it work?',\n",
       " 'Langchain features and benefits',\n",
       " 'Langchain use cases and applications',\n",
       " 'Langchain competitors and alternatives',\n",
       " 'Langchain reviews and user experiences']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_queries = index.get_suggested_search_terms(question)\n",
    "search_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=index.get_search_results(search_queries)\n",
    "#can also access this via index.search_results or get the urls only with index.url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  * https://www.techtarget.com/searchenterpriseai/definition/LangChain\n",
      "  * https://www.ibm.com/topics/langchain\n",
      "  * https://www.producthunt.com/stories/what-is-langchain-how-to-use\n",
      "  * https://aws.amazon.com/what-is/langchain/\n",
      "  * https://blog.enterprisedna.co/what-is-langchain-a-beginners-guide-with-examples/\n",
      "  * https://www.marktechpost.com/2023/12/14/what-is-langchain-use-cases-and-benefits/\n",
      "  * https://lakefs.io/blog/what-is-langchain-ml-architecture/\n",
      "  * https://logankilpatrick.medium.com/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28\n",
      "  * https://js.langchain.com/docs/use_cases\n",
      "  * https://medium.com/@ebruboyaci35/use-cases-with-langchain-e0fd5b0587f1\n",
      "  * https://python.langchain.com/docs/use_cases\n",
      "  * https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynb\n",
      "  * https://www.datacamp.com/tutorial/introduction-to-lanchain-for-data-engineering-and-data-applications\n",
      "  * https://www.reddit.com/r/LocalLLaMA/comments/141ttwt/alternative_to_langchain_for_open_llms/\n",
      "  * https://blog.apify.com/langchain-alternatives/\n",
      "  * https://news.ycombinator.com/item?id=36775475\n",
      "  * https://medium.com/mlearning-ai/the-langchain-alternative-you-absolutely-need-to-master-d508cabfd64a\n",
      "  * https://analyticsindiamag.com/top-9-langchain-alternatives-for-building-ai-agents/\n",
      "  * https://news.ycombinator.com/item?id=36645575\n",
      "  * https://medium.com/the-business-of-ai/dont-use-langchain-yet-f1cb73fc7a0b\n",
      "  * https://github.com/hwchase17/langchain/issues/4772\n",
      "  * https://www.linkedin.com/posts/ben-auffarth_langchain-llms-activity-7130094736203214848-QsOP?trk=public_profile_like_view\n",
      "  * https://docs.smith.langchain.com/evaluation/capturing-feedback\n"
     ]
    }
   ],
   "source": [
    "urllist = f\"\".join(f\"\\n  * {d['href']}\" for i, d in enumerate(results))\n",
    "print(urllist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occurred: HTTPSConnectionPool(host='www.marktechpost.com', port=443): Read timed out. (read timeout=4) \n",
      "----------------------------------------------------------------------------------------------------\n",
      "extracted 22 sites\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.techtarget.com/searchenterpriseai/definition/LangChain \n",
      "\n",
      " The potential of AI technology has been percolating in the background for years. But when ChatGPT, the AI chatbot, began grabbing headlines in early 2023, it put generative AI in the spotlight.\n",
      "This guide is your go-to manual for generative AI, covering its benefits, limits, use cases, prospects and much more.\n",
      "You forgot to provide an Email Address.\n",
      "This email address doesn’t appear to be valid.\n",
      "This email address is already registered. Please log in.\n",
      "You have exceeded the maximum character limi\n"
     ]
    }
   ],
   "source": [
    "documents = index.get_scraped_content()\n",
    "print(\"-\" * 100)\n",
    "print(f\"extracted {len(documents)} sites\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(documents[0].metadata['source'],'\\n\\n',documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Document Splitting is required to split documents into smaller chunks. Document splitting happens after we load data into standardised document format but before it goes into the vector store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default RecursiveSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "How the text is split: by list of characters.\n",
    "How the chunk size is measured: by number of characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "extracted 352 documents from 22 documents\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "split_docs = index.get_split_documents(documents)\n",
    "print(\"-\" * 100)\n",
    "print(f\"extracted {len(split_docs)} documents from {len(documents)} documents\")\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed and Store\n",
    "\n",
    "Let’s start by initializing a simple vector store retriever and storing our docs (in chunks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.get_retriever(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline \n",
    "\n",
    "we can also run all in one like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_retriever = index.run_index_pipeline(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "The retriever had found 4 relevant documents\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "Source: https://aws.amazon.com/what-is/langchain/\n",
      "Title: What is LangChain? - LangChain Explained - AWS\n",
      "Content: How does LangChain work?\n",
      "With LangChain, developers can adapt a language model flexibly to specific business contexts by designating steps required to produce the desired outcome.\n",
      "Chains\n",
      "Chains are the fundamental principle that holds various AI components in LangChain to provide context-aware responses. A chain is a series of automated actions from the user's query to the model's output. For example, developers can use a chain for:\n",
      "Links\n",
      "Chains are made of links. Each action that developers string together to form a chained sequence is called a link. With links, developers can divide complex tasks into multiple, smaller tasks. Examples of links include:\n",
      "In the LangChain framework, a link accepts input from the user and passes it to the LangChain libraries for processing. LangChain also allows link reordering to create different AI workflows.\n",
      "Overview\n",
      "To use LangChain, developers install the framework in Python with the following command:\n",
      "pip install langchain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents('how does langchain work')\n",
    "\n",
    "from ragdoll.helpers import pretty_print_docs\n",
    "print(\"-\" * 100)\n",
    "print(f\"The retriever had found {len(docs)} relevant documents\")\n",
    "print(\"-\" * 100, \"\\n\\n\")\n",
    "print(pretty_print_docs(docs, for_llm=False, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "The retriever had found 4 relevant documents\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "Source: https://aws.amazon.com/what-is/langchain/\n",
      "Title: What is LangChain? - LangChain Explained - AWS\n",
      "Content: How does LangChain work?\n",
      "With LangChain, developers can adapt a language model flexibly to specific business contexts by designating steps required to produce the desired outcome.\n",
      "Chains\n",
      "Chains are the fundamental principle that holds various AI components in LangChain to provide context-aware responses. A chain is a series of automated actions from the user's query to the model's output. For example, developers can use a chain for:\n",
      "Links\n",
      "Chains are made of links. Each action that developers string together to form a chained sequence is called a link. With links, developers can divide complex tasks into multiple, smaller tasks. Examples of links include:\n",
      "In the LangChain framework, a link accepts input from the user and passes it to the LangChain libraries for processing. LangChain also allows link reordering to create different AI workflows.\n",
      "Overview\n",
      "To use LangChain, developers install the framework in Python with the following command:\n",
      "pip install langchain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = pl_retriever.get_relevant_documents('how does langchain work')\n",
    "print(\"-\" * 100)\n",
    "print(f\"The retriever had found {len(docs)} relevant documents\")\n",
    "print(\"-\" * 100, \"\\n\\n\")\n",
    "print(pretty_print_docs(docs, for_llm=False, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
