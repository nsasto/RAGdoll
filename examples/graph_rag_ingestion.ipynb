{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph RAG ingestion pipeline demo\n",
    "\n",
    "This notebook walks through a full ingestion run that loads every document in `tests/test_data`, extracts entities/relationships, and writes both vector and graph stores. Run the cells sequentially to provision dependencies, configure the LLM caller, and persist the resulting artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Install the project dependencies and ensure you can import the `ragdoll` package.\n",
    "2. Export the credentials required by your chosen LLM/embedding providers (for example `OPENAI_API_KEY`).\n",
    "3. (Optional) Clean up `data/vector_stores/graph_rag_demo` and `data/graph_stores/graph_rag_demo` if you want a fresh run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c22ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\dev\\RAGdoll\n",
      "Vector store directory: C:\\dev\\RAGdoll\\data\\vector_stores\\graph_rag_demo\n",
      "Graph store directory: C:\\dev\\RAGdoll\\data\\graph_stores\\graph_rag_demo\n",
      "Graph store file: C:\\dev\\RAGdoll\\data\\graph_stores\\graph_rag_demo\\graph.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def find_project_root(marker: str = \"pyproject.toml\") -> Path:\n",
    "    path = Path.cwd().resolve()\n",
    "    for candidate in (path, *path.parents):\n",
    "        if (candidate / marker).exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Unable to locate the project root—open this notebook inside the repository.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "VECTOR_STORE_DIR = DATA_DIR / \"vector_stores\" / \"graph_rag_demo\"\n",
    "GRAPH_STORE_DIR = DATA_DIR / \"graph_stores\" / \"graph_rag_demo\"\n",
    "GRAPH_STORE_FILE = GRAPH_STORE_DIR / \"graph.pkl\"\n",
    "\n",
    "for directory in (VECTOR_STORE_DIR, GRAPH_STORE_DIR):\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Vector store directory: {VECTOR_STORE_DIR}\")\n",
    "print(f\"Graph store directory: {GRAPH_STORE_DIR}\")\n",
    "print(f\"Graph store file: {GRAPH_STORE_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d9f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM caller ready for gpt-4o.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from ragdoll.pipeline import IngestionOptions, IngestionPipeline\n",
    "from ragdoll.llms import get_llm_caller\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "llm_caller = get_llm_caller(MODEL_NAME)\n",
    "if llm_caller is None:\n",
    "    raise RuntimeError(\"Unable to initialise the requested LLM. Check your configuration or API keys.\")\n",
    "\n",
    "print(f\"LLM caller ready for {MODEL_NAME}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1cd1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 sources:\n",
      "['C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_docx.docx',\n",
      " 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_pdf.pdf',\n",
      " 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_pptx.pptx',\n",
      " 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_txt.txt',\n",
      " 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_xlsx.xlsx']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "test_data_dir = PROJECT_ROOT / \"tests\" / \"test_data\"\n",
    "if not test_data_dir.exists():\n",
    "    raise FileNotFoundError(f\"Could not find {test_data_dir}â€”check your checkout.\")\n",
    "\n",
    "sources = sorted(str(path) for path in test_data_dir.iterdir() if path.is_file())\n",
    "print(f\"Loaded {len(sources)} sources:\")\n",
    "pprint(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd80946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionOptions(batch_size=5, parallel_extraction=False, max_workers=4, skip_vector_store=False, skip_graph_store=False, extract_entities=True, collect_metrics=True, chunking_options={'chunk_size': 1000, 'chunk_overlap': 200}, embedding_options=None, vector_store_options={'store_type': 'chroma', 'params': {'collection_name': 'graph_rag_demo', 'persist_directory': 'C:\\\\dev\\\\RAGdoll\\\\data\\\\vector_stores\\\\graph_rag_demo'}}, graph_store_options={'store_type': 'networkx', 'output_file': 'C:\\\\dev\\\\RAGdoll\\\\data\\\\graph_stores\\\\graph_rag_demo\\\\graph.pkl'}, entity_extraction_options={'entity_types': ['Person', 'Organization', 'Location', 'Date'], 'relationship_types': ['works_for', 'born_in', 'located_in']}, llm=None, llm_caller=<ragdoll.llms.callers.LangChainLLMCaller object at 0x000001CFE0F80050>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = IngestionOptions(\n",
    "    batch_size=5,\n",
    "    parallel_extraction=False,\n",
    "    extract_entities=True,\n",
    "    chunking_options={\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "    },\n",
    "    # Use Chroma because it can be initialized empty; FAISS requires manual index/docstore wiring.\n",
    "    vector_store_options={\n",
    "        \"store_type\": \"chroma\",\n",
    "        \"params\": {\n",
    "            \"collection_name\": \"graph_rag_demo\",\n",
    "            \"persist_directory\": str(VECTOR_STORE_DIR),\n",
    "        },\n",
    "    },\n",
    "    graph_store_options={\n",
    "        \"store_type\": \"networkx\",\n",
    "        \"output_file\": str(GRAPH_STORE_FILE),\n",
    "    },\n",
    "    entity_extraction_options={\n",
    "        \"entity_types\": [\"Person\", \"Organization\", \"Location\", \"Date\"],\n",
    "        \"relationship_types\": [\"works_for\", \"born_in\", \"located_in\"],\n",
    "    },\n",
    "    llm_caller=llm_caller,\n",
    ")\n",
    "\n",
    "options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82993863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ragdoll.config.config_manager:Raw file mappings from config: {'.json': 'langchain_community.document_loaders.JSONLoader', '.jsonl': 'langchain_community.document_loaders.JSONLoader', '.yaml': 'langchain_community.document_loaders.JSONLoader', '.csv': 'langchain_community.document_loaders.CSVLoader', '.epub': 'langchain_markitdown.loaders.EpubLoader', '.xlsx': 'langchain_markitdown.loaders.XlsxLoader', '.html': 'langchain_markitdown.loaders.HtmlLoader', '.bmp': 'langchain_markitdown.loaders.ImageLoader', '.jpeg': 'langchain_markitdown.loaders.ImageLoader', '.jpg': 'langchain_markitdown.loaders.ImageLoader', '.png': 'langchain_markitdown.loaders.ImageLoader', '.tiff': 'langchain_markitdown.loaders.ImageLoader', '.md': 'langchain_community.document_loaders.TextLoader', '.pdf': 'langchain_community.document_loaders.PyMuPDFLoader', '.pptx': 'langchain_markitdown.loaders.PptxLoader', '.docx': 'langchain_markitdown.loaders.DocxLoader', '.xml': 'langchain_markitdown.loaders.RssLoader', '.txt': 'langchain_community.document_loaders.TextLoader', '.rtf': 'langchain_community.document_loaders.RtfLoader', 'arxiv': 'langchain_community.retrievers.ArxivRetriever', 'website': 'langchain_community.document_loaders.WebBaseLoader'}\n",
      "INFO:ragdoll.config.config_manager:For extension .json: loaded JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .jsonl: loaded JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .yaml: loaded JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .csv: loaded CSVLoader from langchain_community.document_loaders.csv_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .epub: loaded EpubLoader from langchain_markitdown.loaders.epub_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .xlsx: loaded XlsxLoader from langchain_markitdown.loaders.xlsx_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .html: loaded HtmlLoader from langchain_markitdown.loaders.html_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .bmp: loaded ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .jpeg: loaded ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .jpg: loaded ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .png: loaded ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .tiff: loaded ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .md: loaded TextLoader from langchain_community.document_loaders.text\n",
      "INFO:ragdoll.config.config_manager:For extension .pdf: loaded PyMuPDFLoader from langchain_community.document_loaders.pdf\n",
      "INFO:ragdoll.config.config_manager:For extension .pptx: loaded PptxLoader from langchain_markitdown.loaders.pptx_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .docx: loaded DocxLoader from langchain_markitdown.loaders.docx_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .xml: loaded RssLoader from langchain_markitdown.loaders.rss_loader\n",
      "INFO:ragdoll.config.config_manager:For extension .txt: loaded TextLoader from langchain_community.document_loaders.text\n",
      "WARNING:ragdoll.config.config_manager:Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping.\n",
      "INFO:ragdoll.config.config_manager:For extension arxiv: loaded ArxivRetriever from langchain_community.retrievers.arxiv\n",
      "INFO:ragdoll.config.config_manager:For extension website: loaded WebBaseLoader from langchain_community.document_loaders.web_base\n",
      "INFO:ragdoll.config.config_manager:Loaded 20 file extension loaders.\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .json -> JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .jsonl -> JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .yaml -> JSONLoader from langchain_community.document_loaders.json_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .csv -> CSVLoader from langchain_community.document_loaders.csv_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .epub -> EpubLoader from langchain_markitdown.loaders.epub_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .xlsx -> XlsxLoader from langchain_markitdown.loaders.xlsx_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .html -> HtmlLoader from langchain_markitdown.loaders.html_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .bmp -> ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .jpeg -> ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .jpg -> ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .png -> ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .tiff -> ImageLoader from langchain_markitdown.loaders.image_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .md -> TextLoader from langchain_community.document_loaders.text\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .pdf -> PyMuPDFLoader from langchain_community.document_loaders.pdf\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .pptx -> PptxLoader from langchain_markitdown.loaders.pptx_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .docx -> DocxLoader from langchain_markitdown.loaders.docx_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .xml -> RssLoader from langchain_markitdown.loaders.rss_loader\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: .txt -> TextLoader from langchain_community.document_loaders.text\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: arxiv -> ArxivRetriever from langchain_community.retrievers.arxiv\n",
      "INFO:ragdoll.config.config_manager:Final loader mapping: website -> WebBaseLoader from langchain_community.document_loaders.web_base\n",
      "INFO:ragdoll.ingestion.document_loaders:Service initialized: loaders=20, max_threads=10\n",
      "INFO:ragdoll.embeddings:Using default embedding model: text-embedding-ada-002\n",
      "ERROR:ragdoll.llms:No model specified and no default model found in config.\n",
      "INFO:ragdoll.graph_stores:Using default graph store: json\n",
      "ERROR:ragdoll.graph_stores:JSON graph store error: _path_exists: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      "INFO:ragdoll.pipeline:Starting ingestion pipeline for 5 sources\n",
      "INFO:ragdoll.ingestion.document_loaders:Starting ingestion of 5 inputs\n",
      "INFO:ragdoll.metrics.metrics_manager:Started metrics session b06676ef-75a8-4dfa-97af-c2bbd0637103 with 5 inputs\n",
      "INFO:ragdoll.ingestion.document_loaders:Using DocxLoader from langchain_markitdown.loaders.docx_loader for C:\\dev\\RAGdoll\\tests\\test_data\\test_docx.docx (extension: .docx)\n",
      "INFO:ragdoll.ingestion.document_loaders:Using PyMuPDFLoader from langchain_community.document_loaders.pdf for C:\\dev\\RAGdoll\\tests\\test_data\\test_pdf.pdf (extension: .pdf)\n",
      "INFO:ragdoll.ingestion.document_loaders:Initializing loader with file_path=C:\\dev\\RAGdoll\\tests\\test_data\\test_docx.docx\n",
      "INFO:ragdoll.ingestion.document_loaders:Using PptxLoader from langchain_markitdown.loaders.pptx_loader for C:\\dev\\RAGdoll\\tests\\test_data\\test_pptx.pptx (extension: .pptx)\n",
      "INFO:ragdoll.ingestion.document_loaders:Using TextLoader from langchain_community.document_loaders.text for C:\\dev\\RAGdoll\\tests\\test_data\\test_txt.txt (extension: .txt)\n",
      "INFO:ragdoll.ingestion.document_loaders:Using XlsxLoader from langchain_markitdown.loaders.xlsx_loader for C:\\dev\\RAGdoll\\tests\\test_data\\test_xlsx.xlsx (extension: .xlsx)\n",
      "INFO:ragdoll.ingestion.document_loaders:Initializing loader with file_path=C:\\dev\\RAGdoll\\tests\\test_data\\test_pdf.pdf\n",
      "INFO:ragdoll.ingestion.document_loaders:Initializing loader with file_path=C:\\dev\\RAGdoll\\tests\\test_data\\test_pptx.pptx\n",
      "INFO:ragdoll.ingestion.document_loaders:Initializing loader with file_path=C:\\dev\\RAGdoll\\tests\\test_data\\test_txt.txt\n",
      "INFO:ragdoll.ingestion.document_loaders:Initializing loader with file_path=C:\\dev\\RAGdoll\\tests\\test_data\\test_xlsx.xlsx\n",
      "INFO:ragdoll.ingestion.document_loaders:Loader TextLoader returned 1 documents from C:\\dev\\RAGdoll\\tests\\test_data\\test_txt.txt\n",
      "INFO:ragdoll.ingestion.document_loaders:Loader PyMuPDFLoader returned 773 documents from C:\\dev\\RAGdoll\\tests\\test_data\\test_pdf.pdf\n",
      "INFO:ragdoll.ingestion.document_loaders:Loader XlsxLoader returned 1 documents from C:\\dev\\RAGdoll\\tests\\test_data\\test_xlsx.xlsx\n",
      "INFO:ragdoll.ingestion.document_loaders:Loader DocxLoader returned 1 documents from C:\\dev\\RAGdoll\\tests\\test_data\\test_docx.docx\n",
      "INFO:ragdoll.ingestion.document_loaders:Loader PptxLoader returned 1 documents from C:\\dev\\RAGdoll\\tests\\test_data\\test_pptx.pptx\n",
      "INFO:ragdoll.metrics.metrics_manager:Metrics session completed and saved to C:\\Users\\nsast\\.ragdoll\\metrics\\session_b06676ef-75a8-4dfa-97af-c2bbd0637103.json\n",
      "INFO:ragdoll.metrics.metrics_manager:Processed 777 documents with 100.0% success rate\n",
      "INFO:ragdoll.ingestion.document_loaders:Finished ingestion: 777 documents\n",
      "INFO:ragdoll.pipeline:Chunking 777 documents using <langchain_text_splitters.markdown.MarkdownTextSplitter object at 0x000001CF90052B40>\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 401 Unauthorized\"\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: os.envir*************_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = IngestionPipeline(options=options)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m stats = \u001b[38;5;28;01mawait\u001b[39;00m pipeline.ingest(sources)\n\u001b[32m      3\u001b[39m stats\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\pipeline\\__init__.py:204\u001b[39m, in \u001b[36mIngestionPipeline.ingest\u001b[39m\u001b[34m(self, sources)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.stats[\u001b[33m\"\u001b[39m\u001b[33mchunks_created\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vector_store \u001b[38;5;129;01mand\u001b[39;00m chunks:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats[\u001b[33m\"\u001b[39m\u001b[33mvector_entries_added\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entity_extractor \u001b[38;5;129;01mand\u001b[39;00m chunks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\vector_stores\\base_vector_store.py:25\u001b[39m, in \u001b[36mBaseVectorStore.add_documents\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: Sequence[Document]) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add documents by delegating to the wrapped VectorStore.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:258\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    257\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m msg = (\n\u001b[32m    260\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:620\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    618\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    624\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:625\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    623\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    624\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:514\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    518\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: os.envir*************_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "pipeline = IngestionPipeline(options=options)\n",
    "stats = await pipeline.ingest(sources)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = getattr(pipeline, \"last_graph\", None)\n",
    "if graph is None:\n",
    "    print(\"No graph was producedâ€”ensure entity extraction is enabled.\")\n",
    "else:\n",
    "    print(f\"Graph nodes: {graph.number_of_nodes()} | edges: {graph.number_of_edges()}\")\n",
    "    sample_nodes = list(graph.nodes())[:5]\n",
    "    sample_edges = list(graph.edges(data=True))[:5]\n",
    "    if sample_nodes:\n",
    "        print(\"\\nSample nodes:\")\n",
    "        for node in sample_nodes:\n",
    "            print(\" -\", node)\n",
    "    if sample_edges:\n",
    "        print(\"\\nSample edges:\")\n",
    "        for edge in sample_edges:\n",
    "            print(\" -\", edge)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eededd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from ragdoll.ragdoll import Ragdoll\n",
    "from ragdoll.pipeline import IngestionOptions\n",
    "\n",
    "async def main():\n",
    "    ragdoll = Ragdoll()\n",
    "    result = await ragdoll.ingest_with_graph(\n",
    "        sources,\n",
    "        options=IngestionOptions(parallel_extraction=False),\n",
    "    )\n",
    "    print(result[\"stats\"])           # ingestion metrics\n",
    "    print(result[\"graph\"])           # pydantic Graph object\n",
    "    retriever = result[\"graph_retriever\"]\n",
    "    answers = retriever.invoke(\"How does the widget fail-safe work?\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a49c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
