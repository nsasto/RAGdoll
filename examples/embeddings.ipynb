{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from ragdoll.config.config_manager import ConfigManager\n",
    "from ragdoll.embeddings import get_embedding_model\n",
    "\n",
    "# Get openai key from .env file\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default (OpenAI)\n",
    "\n",
    "Initialize with default settings (reads from config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RagdollEmbeddings...\n",
      "Retrieving embeddings model...\n",
      "Embedding text...\n",
      "Successfully embedded text.\n",
      "Embedding snippet: [-0.0005520450067706406, 0.011735953390598297, -0.035109445452690125, 0.02787596546113491, 0.014405452646315098, -0.014836017042398453, -0.007485668640583754, 0.01939999870955944, -0.04667317494750023, -0.02443145029246807]...\n",
      "Embedding length: 1024\n",
      "\n",
      "========================================\n",
      "\n",
      "Example with HuggingFace Embeddings\n",
      "Loading configuration for HuggingFace...\n",
      "Retrieving HuggingFace embeddings model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/RAGdoll/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding text with HuggingFace model...\n",
      "Successfully embedded text with HuggingFace model.\n",
      "Embedding snippet (HuggingFace): [0.013939229771494865, -0.07620272785425186, -0.014649280346930027, -0.007813125848770142, -0.07404559850692749, 0.03170468285679817, -0.006173940375447273, 0.0016968112904578447, -0.011640751734375954, -0.02002013847231865]...\n",
      "Embedding length (HuggingFace): 768\n",
      "\n",
      "========================================\n",
      "\n",
      "Example with Custom Configuration\n",
      "Creating a custom configuration...\n",
      "Retrieving custom embeddings model...\n",
      "Embedding text with custom model...\n",
      "Successfully embedded text with custom model.\n",
      "Embedding snippet (Custom): [0.03349284827709198, 0.021506087854504585, -0.023170510306954384, 0.027302365750074387, -0.013154775835573673, -0.02863098308444023, -0.009658029302954674, 0.009234623983502388, -0.004635562188923359, 0.03720129653811455]...\n",
      "Embedding length (Custom): 1536\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration using ConfigManager\n",
    "config_manager = ConfigManager()\n",
    "config = config_manager._config  # type: ignore\n",
    "\n",
    "print(\"Initializing embeddings from config...\")\n",
    "model = get_embedding_model(config_manager=config_manager)\n",
    "print(\"Retrieving embeddings model...\")\n",
    "\n",
    "# Define the text to embed\n",
    "text_to_embed = \"This is an example sentence.\"\n",
    "print(\"Embedding text...\")\n",
    "# Attempt to embed the text using the model\n",
    "try:\n",
    "    embedding = model.embed_query(text_to_embed)\n",
    "    # Print a snippet of the embedding for brevity\n",
    "    print(\"Successfully embedded text.\")\n",
    "    print(f\"Embedding snippet: {embedding[:10]}...\")\n",
    "    print(f\"Embedding length: {len(embedding)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not embed text: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40 + \"\\n\")  # Separator for different examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example with HuggingFace Embeddings\n",
      "Loading configuration for HuggingFace...\n",
      "Retrieving HuggingFace embeddings model...\n",
      "Embedding text with HuggingFace model...\n",
      "Successfully embedded text with HuggingFace model.\n",
      "Embedding snippet (HuggingFace): [0.013939229771494865, -0.07620272785425186, -0.014649280346930027, -0.007813125848770142, -0.07404559850692749, 0.03170468285679817, -0.006173940375447273, 0.0016968112904578447, -0.011640751734375954, -0.02002013847231865]...\n",
      "Embedding length (HuggingFace): 768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of using HuggingFace embeddings model\n",
    "print(\"Example with HuggingFace Embeddings\")\n",
    "print(\"Loading configuration for HuggingFace...\")\n",
    "\n",
    "print(\"Retrieving HuggingFace embeddings model...\")\n",
    "model_hf = get_embedding_model(\n",
    "    provider=\"huggingface\",\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    ")\n",
    "\n",
    "print(\"Embedding text with HuggingFace model...\")\n",
    "try:\n",
    "    embedding_hf = model_hf.embed_query(text_to_embed)\n",
    "    print(\"Successfully embedded text with HuggingFace model.\")\n",
    "    print(f\"Embedding snippet (HuggingFace): {embedding_hf[:10]}...\")\n",
    "    print(f\"Embedding length (HuggingFace): {len(embedding_hf)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not embed text with HuggingFace model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "\n",
      "Example with Custom Configuration\n",
      "Creating a custom configuration...\n",
      "Retrieving custom embeddings model...\n",
      "Embedding text with custom model...\n",
      "Successfully embedded text with custom model.\n",
      "Embedding snippet (Custom): [0.03349284827709198, 0.021506087854504585, -0.023170510306954384, 0.027302365750074387, -0.013154775835573673, -0.02863098308444023, -0.009658029302954674, 0.009234623983502388, -0.004635562188923359, 0.03720129653811455]...\n",
      "Embedding length (Custom): 1536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 40 + \"\\n\")  # Separator for different examples\n",
    "\n",
    "# Example of initializing with a custom configuration\n",
    "print(\"Example with Custom Configuration\")\n",
    "print(\"Creating a custom configuration...\")\n",
    "\n",
    "print(\"Retrieving custom embeddings model...\")\n",
    "model_custom = get_embedding_model(\n",
    "    provider=\"openai\",\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,\n",
    ")\n",
    "\n",
    "print(\"Embedding text with custom model...\")\n",
    "try:\n",
    "    embedding_custom = model_custom.embed_query(text_to_embed)\n",
    "    print(\"Successfully embedded text with custom model.\")\n",
    "    print(f\"Embedding snippet (Custom): {embedding_custom[:10]}...\")\n",
    "    print(f\"Embedding length (Custom): {len(embedding_custom)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not embed text with custom model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}