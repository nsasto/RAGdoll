{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model created: client=<openai.resources.embeddings.Embeddings object at 0x0000022E7521D710> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x0000022E752B9B90> model='text-embedding-ada-002' dimensions=None deployment='text-embedding-ada-002' openai_api_version=None openai_api_base=None openai_api_type=None openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=1000 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True\n",
      "Creating vector store...\n",
      "Vector store created: <langchain_community.vectorstores.faiss.FAISS object at 0x0000022E64FDD090>\n",
      "Saving vector store to ./data/vector_stores/my_faiss\n",
      "Vector store saved successfully\n",
      "Attempting to load vector store from ./data/vector_stores/my_faiss\n",
      "Loaded store: <langchain_community.vectorstores.faiss.FAISS object at 0x0000022E753034D0>\n",
      "Performing search with query: How do RAG systems work?\n",
      "RAG systems combine retrieval with generation\n",
      "--------------------------------------------------\n",
      "This is a test document about AI\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ragdoll.embeddings import get_embedding_model  \n",
    "from ragdoll.vector_stores import get_vector_store\n",
    "import os\n",
    "\n",
    "# Get embedding model\n",
    "embedding_model = get_embedding_model(\"text-embedding-ada-002\")  # Updated model name format\n",
    "print(f\"Embedding model created: {embedding_model}\")\n",
    "\n",
    "# Create a FAISS vector store with documents\n",
    "# For example purposes, let's create some simple test documents\n",
    "from langchain_core.documents import Document\n",
    "documents = [\n",
    "    Document(page_content=\"This is a test document about AI\"),\n",
    "    Document(page_content=\"Vector databases store embeddings for semantic search\"),\n",
    "    Document(page_content=\"RAG systems combine retrieval with generation\")\n",
    "]\n",
    "\n",
    "# Ensure the directory exists\n",
    "persist_dir = \"./data/vector_stores/my_faiss\"\n",
    "os.makedirs(persist_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Creating vector store...\")\n",
    "vector_store = get_vector_store(\n",
    "    store_type=\"faiss\", \n",
    "    embedding_model=embedding_model,\n",
    "    documents=documents,\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "\n",
    "print(f\"Vector store created: {vector_store}\")\n",
    "\n",
    "# Save it - Note: With persist_directory, FAISS may have already saved the index\n",
    "if vector_store is not None and hasattr(vector_store, \"save_local\"):\n",
    "    print(f\"Saving vector store to {persist_dir}\")\n",
    "    vector_store.save_local(persist_dir)\n",
    "    print(\"Vector store saved successfully\")\n",
    "\n",
    "# Later, load it back\n",
    "print(f\"Attempting to load vector store from {persist_dir}\")\n",
    "loaded_store = get_vector_store(\n",
    "    store_type=\"faiss\",\n",
    "    embedding_model=embedding_model,\n",
    "    persist_directory=persist_dir,\n",
    "    allow_dangerous_deserialization=True  # Add this parameter\n",
    ")\n",
    "print(f\"Loaded store: {loaded_store}\")\n",
    "\n",
    "# You can now perform similarity searches\n",
    "if loaded_store is not None:\n",
    "    query = \"How do RAG systems work?\"\n",
    "    print(f\"Performing search with query: {query}\")\n",
    "    results = loaded_store.similarity_search(query, k=2)\n",
    "    for doc in results:\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"Failed to load vector store. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd6a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
