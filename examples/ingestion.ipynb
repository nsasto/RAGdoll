{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbdbf6d",
   "metadata": {},
   "source": [
    "# Ingestion Service\n",
    "\n",
    "Some basic usage examples of the RagDoll2 ingestion service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100a982",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "\n",
    "# Get absolute path to the test_data directory\n",
    "current_file = Path(os.path.abspath(\"\"))  # Current notebook directory\n",
    "test_data_dir = (current_file.parent / \"tests\" / \"test_data\").resolve()\n",
    "\n",
    "# Find all files using glob\n",
    "file_paths = glob.glob(str(test_data_dir / \"*\"))\n",
    "print(f\"Found {len(file_paths)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50c3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:11,593 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:11,600 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:13,661 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:14,241 - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "2025-04-23 09:56:14,244 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:14,247 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:56:14,249 - INFO - Starting ingestion of 5 inputs\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
      "/home/user/RAGdoll/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "2025-04-23 09:56:30,963 - INFO - Finished ingestion: 777 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 777 documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create ingestion service with default settings\n",
    "service = IngestionService()\n",
    "\n",
    "# Process all documents\n",
    "documents = service.ingest_documents(file_paths)\n",
    "\n",
    "# Show how many documents were extracted\n",
    "print(f\"Processed {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50a3d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document content (preview): <!-- Slide number: 1 -->\n",
      "# Shapes\n",
      "\n",
      "Transparent\n",
      "\n",
      "<!-- Slide number: 2 -->\n",
      "a\n",
      "\n",
      "Restart\n",
      "\n",
      "<!-- Slide numb...\n",
      "Metadata:\n",
      " {\n",
      "  \"source\": \"/home/user/RAGdoll/tests/test_data/test_pptx.pptx\",\n",
      "  \"file_name\": \"test_pptx.pptx\",\n",
      "  \"file_size\": 217939,\n",
      "  \"conversion_success\": true,\n",
      "  \"slide_count\": 8,\n",
      "  \"author\": \"Lingineni, Raviteja\",\n",
      "  \"title\": \"feedback@customer.cool\",\n",
      "  \"created\": \"2018-06-23 03:43:30\",\n",
      "  \"modified\": \"2025-04-16 15:42:35\",\n",
      "  \"last_modified_by\": \"Nathan Sasto\",\n",
      "  \"revision\": \"52\",\n",
      "  \"image_count\": 12,\n",
      "  \"text_box_count\": 2,\n",
      "  \"chart_count\": 0,\n",
      "  \"table_count\": 0,\n",
      "  \"content_type\": \"presentation_full\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Access the first document\n",
    "if documents:\n",
    "    doc = documents[0]\n",
    "    print(f\"First document content (preview): {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata:\\n {json.dumps(doc.metadata, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a8122",
   "metadata": {},
   "source": [
    "## Working with different file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:31,055 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:31,058 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:56:31,060 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:31,061 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:31,062 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:56:31,064 - INFO - Starting ingestion of 1 inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:37,978 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:56:37,980 - INFO - Starting ingestion of 2 inputs\n",
      "2025-04-23 09:56:37,984 - INFO - Finished ingestion: 2 documents\n",
      "2025-04-23 09:56:37,986 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:56:38,673 - INFO - Finished ingestion: 1 documents\n",
      "2025-04-23 09:56:38,674 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:56:40,021 - INFO - Finished ingestion: 1 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 777\n",
      "Documents by type:\n",
      "  - PDF: 773\n",
      "  - Text: 2\n",
      "  - DOCX: 1\n",
      "  - Web: 1\n"
     ]
    }
   ],
   "source": [
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "\n",
    "# Initialize service\n",
    "service = IngestionService()\n",
    "\n",
    "# Process files of different types\n",
    "pdf_docs = service.ingest_documents([\"../tests/test_data/test_pdf.pdf\"])\n",
    "text_docs = service.ingest_documents([\"../tests/test_data/test_txt.txt\", \"../tests/test_data/test_txt.txt\"])\n",
    "docx_docs = service.ingest_documents([\"../tests/test_data/test_docx.docx\"])\n",
    "\n",
    "# Process HTML from URLs\n",
    "web_docs = service.ingest_documents([\"https://github.com/nsasto/langchain-markitdown\"])\n",
    "\n",
    "# Combine all documents\n",
    "all_docs = pdf_docs + text_docs + docx_docs + web_docs\n",
    "\n",
    "print(f\"Total documents: {len(all_docs)}\")\n",
    "print(f\"Documents by type:\")\n",
    "print(f\"  - PDF: {len(pdf_docs)}\")\n",
    "print(f\"  - Text: {len(text_docs)}\")\n",
    "print(f\"  - DOCX: {len(docx_docs)}\")\n",
    "print(f\"  - Web: {len(web_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae935eb",
   "metadata": {},
   "source": [
    "## Customizing Ingestion Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06757cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:40,052 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:40,054 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:56:40,056 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:40,057 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:40,058 - INFO - Service initialized: loaders=20, max_threads=4\n",
      "2025-04-23 09:56:40,060 - INFO - Starting ingestion of 5 inputs\n",
      "2025-04-23 09:56:40,061 - INFO - Started metrics session c02b6ec7-8e77-4e11-a140-f0c88ebc0d3e with 5 inputs\n",
      "2025-04-23 09:56:46,164 - INFO - Metrics session completed and saved to /home/user/.ragdoll/metrics/session_c02b6ec7-8e77-4e11-a140-f0c88ebc0d3e.json\n",
      "2025-04-23 09:56:46,166 - INFO - Processed 777 documents with 100.0% success rate\n",
      "2025-04-23 09:56:46,167 - INFO - Finished ingestion: 777 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 777 document chunks\n",
      "First document size: 1043 characters\n"
     ]
    }
   ],
   "source": [
    "# Modified initialization with supported parameters\n",
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "\n",
    "# Initialize with only the supported parameters\n",
    "service = IngestionService(\n",
    "    max_threads=4,                # Limit concurrency\n",
    "    batch_size=10,                # Process files in batches of 10\n",
    "    use_cache=True,               # Enable caching\n",
    "    collect_metrics=True          # Enable metrics collection\n",
    ")\n",
    "\n",
    "# Process documents - pass file_paths directly, not [file_paths]\n",
    "documents = service.ingest_documents(file_paths)\n",
    "\n",
    "print(f\"Processed {len(documents)} document chunks\")\n",
    "\n",
    "# Document properties can be accessed differently depending on type\n",
    "if documents:\n",
    "    doc = documents[0]\n",
    "    if hasattr(doc, 'page_content'):\n",
    "        content_length = len(doc.page_content)\n",
    "    elif isinstance(doc, dict) and 'page_content' in doc:\n",
    "        content_length = len(doc['page_content'])\n",
    "    else:\n",
    "        content_length = 0\n",
    "    print(f\"First document size: {content_length} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db81bcb",
   "metadata": {},
   "source": [
    "## Working with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bc5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:46,206 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:46,208 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:56:46,209 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:46,210 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:46,212 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:56:46,244 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:46,245 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:56:46,247 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:46,249 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:46,253 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:56:46,254 - INFO - Starting ingestion of 1 inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache cleared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:56:49,991 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:56:50,492 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:56:54,094 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:56:54,596 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:56:58,014 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:56:58,032 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:56:58,034 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:56:58,035 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:56:58,037 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:56:58,038 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:56:58,039 - INFO - Starting ingestion of 1 inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without cache:\n",
      "  Processed 773 documents\n",
      "  Average time: 3.588 seconds\n",
      "  Min time: 3.421, Max time: 3.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:57:01,529 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:57:02,030 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:57:05,501 - INFO - Finished ingestion: 773 documents\n",
      "2025-04-23 09:57:06,004 - INFO - Starting ingestion of 1 inputs\n",
      "2025-04-23 09:57:09,443 - INFO - Finished ingestion: 773 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With cache:\n",
      "  Processed 773 documents\n",
      "  Average time: 3.468 seconds\n",
      "  Min time: 3.442, Max time: 3.491\n",
      "\n",
      "Cache performance improvement: 3.3%\n"
     ]
    }
   ],
   "source": [
    "# Complete caching performance test\n",
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "def measure_processing_time(use_cache, file_path, runs=3):\n",
    "    \"\"\"Measure document processing time with or without cache.\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    service = IngestionService(use_cache=use_cache)\n",
    "    \n",
    "    # Run multiple times to get average performance\n",
    "    for i in range(runs):\n",
    "        start = time.time()\n",
    "        docs = service.ingest_documents([file_path])\n",
    "        elapsed = time.time() - start\n",
    "        times.append(elapsed)\n",
    "        \n",
    "        # Don't sleep on the last run\n",
    "        if i < runs-1:\n",
    "            time.sleep(0.5)  # Short pause between runs\n",
    "    \n",
    "    return {\n",
    "        \"avg_time\": statistics.mean(times),\n",
    "        \"min_time\": min(times),\n",
    "        \"max_time\": max(times),\n",
    "        \"doc_count\": len(docs),\n",
    "        \"runs\": runs\n",
    "    }\n",
    "\n",
    "# Clear any existing cache first\n",
    "service_clear = IngestionService(use_cache=True)\n",
    "service_clear.clear_cache()\n",
    "print(\"Cache cleared\")\n",
    "\n",
    "# Test with no cache\n",
    "no_cache_results = measure_processing_time(False, \"../tests/test_data/test_pdf.pdf\", runs=3)\n",
    "print(\"\\nWithout cache:\")\n",
    "print(f\"  Processed {no_cache_results['doc_count']} documents\")\n",
    "print(f\"  Average time: {no_cache_results['avg_time']:.3f} seconds\")\n",
    "print(f\"  Min time: {no_cache_results['min_time']:.3f}, Max time: {no_cache_results['max_time']:.3f}\")\n",
    "\n",
    "# Test with cache (first run populates, subsequent runs use cache)\n",
    "cache_results = measure_processing_time(True, \"../tests/test_data/test_pdf.pdf\", runs=3)\n",
    "print(\"\\nWith cache:\")\n",
    "print(f\"  Processed {cache_results['doc_count']} documents\")\n",
    "print(f\"  Average time: {cache_results['avg_time']:.3f} seconds\")\n",
    "print(f\"  Min time: {cache_results['min_time']:.3f}, Max time: {cache_results['max_time']:.3f}\")\n",
    "\n",
    "# Speed improvement calculation\n",
    "if no_cache_results['avg_time'] > 0:\n",
    "    improvement = (no_cache_results['avg_time'] - cache_results['avg_time']) / no_cache_results['avg_time'] * 100\n",
    "    print(f\"\\nCache performance improvement: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e15e5",
   "metadata": {},
   "source": [
    "## Handling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c071a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:57:09,477 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:57:09,478 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:57:09,480 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:57:09,482 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:57:09,483 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:57:09,485 - INFO - Starting ingestion of 4 inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during ingestion: No valid sources found\n"
     ]
    }
   ],
   "source": [
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "import logging\n",
    "\n",
    "# Configure logging to see warnings and errors\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Create service\n",
    "service = IngestionService()\n",
    "\n",
    "# Mix of valid and invalid files\n",
    "files = [\n",
    "    \"documents/valid.pdf\",\n",
    "    \"documents/corrupted.pdf\",\n",
    "    \"documents/nonexistent.txt\",\n",
    "    \"documents/valid.txt\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Service will skip files it can't process\n",
    "    documents = service.ingest_documents(files)\n",
    "    print(f\"Successfully processed {len(documents)} documents\")\n",
    "    \n",
    "    # Check how many files were actually processed\n",
    "    sources = set([doc['metadata'].get('source') for doc in documents if 'source' in doc['metadata']])\n",
    "    print(f\"Documents came from {len(sources)} source files\")\n",
    "    print(f\"Source files: {sources}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during ingestion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea98b7",
   "metadata": {},
   "source": [
    "## Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09343461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files\n"
     ]
    }
   ],
   "source": [
    "# Replace your current loading code with this\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from ragdoll.ingestion.ingestion_service import IngestionService\n",
    "\n",
    "# Get absolute path to the test_data directory\n",
    "current_file = Path(os.path.abspath(\"\"))  # Current notebook directory\n",
    "test_data_dir = (current_file.parent / \"tests\" / \"test_data\").resolve()\n",
    "\n",
    "# Instead of using Path.glob(), use the glob module which handles absolute paths\n",
    "file_paths = glob.glob(str(test_data_dir / \"*\"))\n",
    "print(f\"Found {len(file_paths)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f60ef0",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2f235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:57:09,536 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:57:09,537 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:57:09,539 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:57:09,541 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:57:09,542 - INFO - Service initialized: loaders=20, max_threads=10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'enabled': True,\n",
       " 'recent_sessions': [{'session_id': 'c02b6ec7-8e77-4e11-a140-f0c88ebc0d3e',\n",
       "   'timestamp_start': '2025-04-23T09:56:40.061580',\n",
       "   'timestamp_end': '2025-04-23T09:56:46.138679',\n",
       "   'input_count': 5,\n",
       "   'success_count': 5,\n",
       "   'failure_count': 0,\n",
       "   'document_count': 777,\n",
       "   'total_bytes': 3434368,\n",
       "   'total_processing_time_ms': 20144,\n",
       "   'sources': {'/home/user/RAGdoll/tests/test_data/test_txt.txt': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_txt.txt',\n",
       "     'source_type': '.txt',\n",
       "     'timestamp_start': '2025-04-23T09:56:40.068445',\n",
       "     'timestamp_end': '2025-04-23T09:56:40.069221',\n",
       "     'processing_time_ms': 0,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 48,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_docx.docx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_docx.docx',\n",
       "     'source_type': '.docx',\n",
       "     'timestamp_start': '2025-04-23T09:56:40.067262',\n",
       "     'timestamp_end': '2025-04-23T09:56:42.299904',\n",
       "     'processing_time_ms': 2232,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 327119,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pdf.pdf': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pdf.pdf',\n",
       "     'source_type': '.pdf',\n",
       "     'timestamp_start': '2025-04-23T09:56:40.074990',\n",
       "     'timestamp_end': '2025-04-23T09:56:46.003762',\n",
       "     'processing_time_ms': 5928,\n",
       "     'success': True,\n",
       "     'document_count': 773,\n",
       "     'bytes': 2860047,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx',\n",
       "     'source_type': '.xlsx',\n",
       "     'timestamp_start': '2025-04-23T09:56:40.092887',\n",
       "     'timestamp_end': '2025-04-23T09:56:46.006816',\n",
       "     'processing_time_ms': 5913,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 29215,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pptx.pptx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pptx.pptx',\n",
       "     'source_type': '.pptx',\n",
       "     'timestamp_start': '2025-04-23T09:56:40.063639',\n",
       "     'timestamp_end': '2025-04-23T09:56:46.135145',\n",
       "     'processing_time_ms': 6071,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 217939,\n",
       "     'error': None}},\n",
       "   'duration_seconds': 6.077099,\n",
       "   'success_rate': 1.0},\n",
       "  {'session_id': 'dd9eb4fc-0575-4fc4-b38c-eac636c43963',\n",
       "   'timestamp_start': '2025-04-22T13:40:48.143342',\n",
       "   'timestamp_end': '2025-04-22T13:40:49.905647',\n",
       "   'input_count': 5,\n",
       "   'success_count': 2,\n",
       "   'failure_count': 3,\n",
       "   'document_count': 774,\n",
       "   'total_bytes': 2860095,\n",
       "   'total_processing_time_ms': 1765,\n",
       "   'sources': {'/home/user/RAGdoll/tests/test_data/test_pptx.pptx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pptx.pptx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:48.146204',\n",
       "     'timestamp_end': '2025-04-22T13:40:48.148731',\n",
       "     'processing_time_ms': 2,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.pptx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_docx.docx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_docx.docx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:48.148561',\n",
       "     'timestamp_end': '2025-04-22T13:40:48.151712',\n",
       "     'processing_time_ms': 3,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.docx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_txt.txt': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_txt.txt',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:48.149782',\n",
       "     'timestamp_end': '2025-04-22T13:40:48.153845',\n",
       "     'processing_time_ms': 4,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 48,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:48.151798',\n",
       "     'timestamp_end': '2025-04-22T13:40:48.155038',\n",
       "     'processing_time_ms': 3,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.xlsx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pdf.pdf': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pdf.pdf',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:48.151241',\n",
       "     'timestamp_end': '2025-04-22T13:40:49.905062',\n",
       "     'processing_time_ms': 1753,\n",
       "     'success': True,\n",
       "     'document_count': 773,\n",
       "     'bytes': 2860047,\n",
       "     'error': None}},\n",
       "   'duration_seconds': 1.762305,\n",
       "   'success_rate': 0.4},\n",
       "  {'session_id': '3c2f6a88-f8b2-47ea-b92b-5faa8d43fd97',\n",
       "   'timestamp_start': '2025-04-22T13:40:33.980228',\n",
       "   'timestamp_end': '2025-04-22T13:40:35.681944',\n",
       "   'input_count': 5,\n",
       "   'success_count': 2,\n",
       "   'failure_count': 3,\n",
       "   'document_count': 774,\n",
       "   'total_bytes': 2860095,\n",
       "   'total_processing_time_ms': 1728,\n",
       "   'sources': {'/home/user/RAGdoll/tests/test_data/test_docx.docx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_docx.docx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:33.983683',\n",
       "     'timestamp_end': '2025-04-22T13:40:33.985847',\n",
       "     'processing_time_ms': 2,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.docx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pptx.pptx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pptx.pptx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:33.983337',\n",
       "     'timestamp_end': '2025-04-22T13:40:33.988320',\n",
       "     'processing_time_ms': 4,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.pptx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_txt.txt': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_txt.txt',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:33.985623',\n",
       "     'timestamp_end': '2025-04-22T13:40:33.990965',\n",
       "     'processing_time_ms': 5,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 48,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:33.988418',\n",
       "     'timestamp_end': '2025-04-22T13:40:34.011595',\n",
       "     'processing_time_ms': 23,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.xlsx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pdf.pdf': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pdf.pdf',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:40:33.987234',\n",
       "     'timestamp_end': '2025-04-22T13:40:35.681423',\n",
       "     'processing_time_ms': 1694,\n",
       "     'success': True,\n",
       "     'document_count': 773,\n",
       "     'bytes': 2860047,\n",
       "     'error': None}},\n",
       "   'duration_seconds': 1.701716,\n",
       "   'success_rate': 0.4},\n",
       "  {'session_id': '5a3f7d2a-77ef-4750-b764-c85b05bfee8b',\n",
       "   'timestamp_start': '2025-04-22T13:10:23.857110',\n",
       "   'timestamp_end': '2025-04-22T13:10:25.548713',\n",
       "   'input_count': 5,\n",
       "   'success_count': 2,\n",
       "   'failure_count': 3,\n",
       "   'document_count': 774,\n",
       "   'total_bytes': 2860095,\n",
       "   'total_processing_time_ms': 1775,\n",
       "   'sources': {'/home/user/RAGdoll/tests/test_data/test_pptx.pptx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pptx.pptx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:23.859893',\n",
       "     'timestamp_end': '2025-04-22T13:10:23.862870',\n",
       "     'processing_time_ms': 2,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.pptx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_docx.docx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_docx.docx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:23.861379',\n",
       "     'timestamp_end': '2025-04-22T13:10:23.865421',\n",
       "     'processing_time_ms': 4,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.docx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:23.864556',\n",
       "     'timestamp_end': '2025-04-22T13:10:23.896231',\n",
       "     'processing_time_ms': 31,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.xlsx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_txt.txt': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_txt.txt',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:23.861829',\n",
       "     'timestamp_end': '2025-04-22T13:10:23.915375',\n",
       "     'processing_time_ms': 53,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 48,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pdf.pdf': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pdf.pdf',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:23.862962',\n",
       "     'timestamp_end': '2025-04-22T13:10:25.548140',\n",
       "     'processing_time_ms': 1685,\n",
       "     'success': True,\n",
       "     'document_count': 773,\n",
       "     'bytes': 2860047,\n",
       "     'error': None}},\n",
       "   'duration_seconds': 1.691603,\n",
       "   'success_rate': 0.4},\n",
       "  {'session_id': '05554771-a60c-40a9-a71a-48b8dc882a8b',\n",
       "   'timestamp_start': '2025-04-22T13:10:09.835738',\n",
       "   'timestamp_end': '2025-04-22T13:10:11.573134',\n",
       "   'input_count': 5,\n",
       "   'success_count': 2,\n",
       "   'failure_count': 3,\n",
       "   'document_count': 774,\n",
       "   'total_bytes': 2860095,\n",
       "   'total_processing_time_ms': 1800,\n",
       "   'sources': {'/home/user/RAGdoll/tests/test_data/test_docx.docx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_docx.docx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:09.839399',\n",
       "     'timestamp_end': '2025-04-22T13:10:09.842373',\n",
       "     'processing_time_ms': 2,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.docx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_txt.txt': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_txt.txt',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:09.839714',\n",
       "     'timestamp_end': '2025-04-22T13:10:09.844480',\n",
       "     'processing_time_ms': 4,\n",
       "     'success': True,\n",
       "     'document_count': 1,\n",
       "     'bytes': 48,\n",
       "     'error': None},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pptx.pptx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pptx.pptx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:09.839078',\n",
       "     'timestamp_end': '2025-04-22T13:10:09.868272',\n",
       "     'processing_time_ms': 29,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.pptx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_xlsx.xlsx',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:09.842460',\n",
       "     'timestamp_end': '2025-04-22T13:10:09.877147',\n",
       "     'processing_time_ms': 34,\n",
       "     'success': False,\n",
       "     'document_count': 0,\n",
       "     'bytes': 0,\n",
       "     'error': 'Unsupported source: type=SourceType.FILE, ext=.xlsx'},\n",
       "    '/home/user/RAGdoll/tests/test_data/test_pdf.pdf': {'batch_id': 1,\n",
       "     'source_id': '/home/user/RAGdoll/tests/test_data/test_pdf.pdf',\n",
       "     'source_type': 'file',\n",
       "     'timestamp_start': '2025-04-22T13:10:09.840793',\n",
       "     'timestamp_end': '2025-04-22T13:10:11.572583',\n",
       "     'processing_time_ms': 1731,\n",
       "     'success': True,\n",
       "     'document_count': 773,\n",
       "     'bytes': 2860047,\n",
       "     'error': None}},\n",
       "   'duration_seconds': 1.737396,\n",
       "   'success_rate': 0.4}],\n",
       " 'aggregate': {'total_sessions': 17,\n",
       "  'total_documents': 13161,\n",
       "  'total_sources': 85,\n",
       "  'successful_sources': 37,\n",
       "  'failed_sources': 48,\n",
       "  'avg_success_rate': 0.43529411764705883,\n",
       "  'avg_documents_per_source': 154.83529411764707,\n",
       "  'avg_processing_time_ms': 584.5176470588235,\n",
       "  'by_source_type': {'file': {'count': 80,\n",
       "    'success_count': 32,\n",
       "    'document_count': 12384,\n",
       "    'total_processing_time_ms': 29540,\n",
       "    'avg_processing_time_ms': 369.25,\n",
       "    'avg_documents': 154.8,\n",
       "    'success_rate': 0.4},\n",
       "   '.txt': {'count': 1,\n",
       "    'success_count': 1,\n",
       "    'document_count': 1,\n",
       "    'total_processing_time_ms': 0,\n",
       "    'avg_processing_time_ms': 0.0,\n",
       "    'avg_documents': 1.0,\n",
       "    'success_rate': 1.0},\n",
       "   '.docx': {'count': 1,\n",
       "    'success_count': 1,\n",
       "    'document_count': 1,\n",
       "    'total_processing_time_ms': 2232,\n",
       "    'avg_processing_time_ms': 2232.0,\n",
       "    'avg_documents': 1.0,\n",
       "    'success_rate': 1.0},\n",
       "   '.pdf': {'count': 1,\n",
       "    'success_count': 1,\n",
       "    'document_count': 773,\n",
       "    'total_processing_time_ms': 5928,\n",
       "    'avg_processing_time_ms': 5928.0,\n",
       "    'avg_documents': 773.0,\n",
       "    'success_rate': 1.0},\n",
       "   '.xlsx': {'count': 1,\n",
       "    'success_count': 1,\n",
       "    'document_count': 1,\n",
       "    'total_processing_time_ms': 5913,\n",
       "    'avg_processing_time_ms': 5913.0,\n",
       "    'avg_documents': 1.0,\n",
       "    'success_rate': 1.0},\n",
       "   '.pptx': {'count': 1,\n",
       "    'success_count': 1,\n",
       "    'document_count': 1,\n",
       "    'total_processing_time_ms': 6071,\n",
       "    'avg_processing_time_ms': 6071.0,\n",
       "    'avg_documents': 1.0,\n",
       "    'success_rate': 1.0}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create service\n",
    "service = IngestionService(collect_metrics=True)\n",
    "metrics = service.get_metrics(days=30) \n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03f74be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:57:09,791 - INFO - Cache initialized at /home/user/.ragdoll/cache with TTL=3600s\n",
      "2025-04-23 09:57:09,792 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n",
      "2025-04-23 09:57:09,794 - WARNING - Module langchain_community.document_loaders does not have attribute RtfLoader for extension .rtf. Skipping this loader.\n",
      "2025-04-23 09:57:09,795 - INFO - Loaded 20 file extension loaders\n",
      "2025-04-23 09:57:09,797 - INFO - Service initialized: loaders=20, max_threads=10\n",
      "2025-04-23 09:57:09,798 - INFO - Starting ingestion of 5 inputs\n",
      "2025-04-23 09:57:09,799 - INFO - Started metrics session 2e22ea27-a84a-4ad0-852a-3e2dd85323d0 with 5 inputs\n",
      "2025-04-23 09:57:15,888 - INFO - Metrics session completed and saved to /home/user/.ragdoll/metrics/session_2e22ea27-a84a-4ad0-852a-3e2dd85323d0.json\n",
      "2025-04-23 09:57:15,889 - INFO - Processed 777 documents with 100.0% success rate\n",
      "2025-04-23 09:57:15,891 - INFO - Finished ingestion: 777 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents processed: 13938\n",
      "Average success rate: 46.67%\n",
      "\n",
      "Metrics for file sources:\n",
      "  Count: 80\n",
      "  Success rate: 40.00%\n",
      "  Average documents: 154.8\n",
      "  Average processing time: 369.2ms\n",
      "\n",
      "Metrics for .txt sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Average documents: 1.0\n",
      "  Average processing time: 12.0ms\n",
      "\n",
      "Metrics for .docx sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Average documents: 1.0\n",
      "  Average processing time: 2403.0ms\n",
      "\n",
      "Metrics for .pdf sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Average documents: 773.0\n",
      "  Average processing time: 5934.0ms\n",
      "\n",
      "Metrics for .xlsx sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Average documents: 1.0\n",
      "  Average processing time: 5868.0ms\n",
      "\n",
      "Metrics for .pptx sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Average documents: 1.0\n",
      "  Average processing time: 6077.5ms\n",
      "\n",
      "Latest session (2e22ea27-a84a-4ad0-852a-3e2dd85323d0):\n",
      "  Time: 2025-04-23T09:57:09.799363\n",
      "  Documents: 777\n",
      "  Duration: 6.09 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create service\n",
    "service = IngestionService(collect_metrics=True)\n",
    "\n",
    "# Pass the actual file paths, not the glob pattern\n",
    "service.ingest_documents(file_paths)\n",
    "\n",
    "\n",
    "# Get metrics after running\n",
    "metrics = service.get_metrics(days=30)  # Get metrics from the last 30 days\n",
    "\n",
    "# Use the metrics data\n",
    "print(f\"Total documents processed: {metrics['aggregate']['total_documents']}\")\n",
    "print(f\"Average success rate: {metrics['aggregate']['avg_success_rate']:.2%}\")\n",
    "\n",
    "# Print metrics for each source type\n",
    "for source_type, type_metrics in metrics['aggregate']['by_source_type'].items():\n",
    "    print(f\"\\nMetrics for {source_type} sources:\")\n",
    "    print(f\"  Count: {type_metrics['count']}\")\n",
    "    print(f\"  Success rate: {type_metrics['success_rate']:.2%}\")\n",
    "    print(f\"  Average documents: {type_metrics['avg_documents']:.1f}\")\n",
    "    print(f\"  Average processing time: {type_metrics['avg_processing_time_ms']:.1f}ms\")\n",
    "\n",
    "# Get the most recent session details\n",
    "if metrics['recent_sessions']:\n",
    "    latest = metrics['recent_sessions'][0]\n",
    "    print(f\"\\nLatest session ({latest['session_id']}):\")\n",
    "    print(f\"  Time: {latest['timestamp_start']}\")\n",
    "    print(f\"  Documents: {latest['document_count']}\")\n",
    "    print(f\"  Duration: {latest['duration_seconds']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5cb4d",
   "metadata": {},
   "source": [
    "### Direct Access\n",
    "\n",
    "You can also access metrics directly from the metrics directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d096cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: 2e22ea27-a84a-4ad0-852a-3e2dd85323d0\n",
      "Date: 2025-04-23T09:57:09.799363\n",
      "Documents processed: 777\n",
      "Success rate: 100.00%\n",
      "\n",
      "Source: /home/user/RAGdoll/tests/test_data/test_txt.txt\n",
      "  Type: .txt\n",
      "  Success: True\n",
      "  Documents: 1\n",
      "  Processing time: 24ms\n",
      "\n",
      "Source: /home/user/RAGdoll/tests/test_data/test_docx.docx\n",
      "  Type: .docx\n",
      "  Success: True\n",
      "  Documents: 1\n",
      "  Processing time: 2574ms\n",
      "\n",
      "Source: /home/user/RAGdoll/tests/test_data/test_xlsx.xlsx\n",
      "  Type: .xlsx\n",
      "  Success: True\n",
      "  Documents: 1\n",
      "  Processing time: 5823ms\n",
      "\n",
      "Source: /home/user/RAGdoll/tests/test_data/test_pdf.pdf\n",
      "  Type: .pdf\n",
      "  Success: True\n",
      "  Documents: 773\n",
      "  Processing time: 5940ms\n",
      "\n",
      "Source: /home/user/RAGdoll/tests/test_data/test_pptx.pptx\n",
      "  Type: .pptx\n",
      "  Success: True\n",
      "  Documents: 1\n",
      "  Processing time: 6084ms\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Default metrics location\n",
    "metrics_dir = Path.home() / \".ragdoll\" / \"metrics\"\n",
    "# Or custom location if you specified one\n",
    "# metrics_dir = Path(\"/path/to/your/metrics\")\n",
    "\n",
    "# List all session files\n",
    "session_files = list(metrics_dir.glob(\"session_*.json\"))\n",
    "# Sort by modification time (most recent first)\n",
    "session_files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "# Read the most recent session\n",
    "if session_files:\n",
    "    with open(session_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "        latest_session = json.load(f)\n",
    "        \n",
    "    print(f\"Session ID: {latest_session['session_id']}\")\n",
    "    print(f\"Date: {latest_session['timestamp_start']}\")\n",
    "    print(f\"Documents processed: {latest_session['document_count']}\")\n",
    "    print(f\"Success rate: {latest_session['success_rate']:.2%}\")\n",
    "    \n",
    "    # Print details about each source\n",
    "    for source_id, source_data in latest_session[\"sources\"].items():\n",
    "        print(f\"\\nSource: {source_id}\")\n",
    "        print(f\"  Type: {source_data['source_type']}\")\n",
    "        print(f\"  Success: {source_data['success']}\")\n",
    "        print(f\"  Documents: {source_data['document_count']}\")\n",
    "        print(f\"  Processing time: {source_data['processing_time_ms']}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4fa95",
   "metadata": {},
   "source": [
    "### Displaying Outputs\n",
    "\n",
    "Simple Metrics dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7ce8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 09:57:15,966 - INFO - Metrics system initialized with storage at /home/user/.ragdoll/metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "  RAGdoll Metrics Dashboard\n",
      "================================================================================\n",
      "Showing metrics for the past 30 days:\n",
      "  Total sessions: 18\n",
      "  Total documents: 13938\n",
      "  Total sources: 90\n",
      "  Success rate: 46.67%\n",
      "  Avg processing time: 779.2ms per source\n",
      "\n",
      "================================================================================\n",
      "  Metrics by Source Type\n",
      "================================================================================\n",
      "\n",
      "FILE Sources:\n",
      "  Count: 80\n",
      "  Success rate: 40.00%\n",
      "  Avg documents: 154.8 per source\n",
      "  Avg processing time: 369.2ms\n",
      "\n",
      ".TXT Sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Avg documents: 1.0 per source\n",
      "  Avg processing time: 12.0ms\n",
      "\n",
      ".DOCX Sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Avg documents: 1.0 per source\n",
      "  Avg processing time: 2403.0ms\n",
      "\n",
      ".PDF Sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Avg documents: 773.0 per source\n",
      "  Avg processing time: 5934.0ms\n",
      "\n",
      ".XLSX Sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Avg documents: 1.0 per source\n",
      "  Avg processing time: 5868.0ms\n",
      "\n",
      ".PPTX Sources:\n",
      "  Count: 2\n",
      "  Success rate: 100.00%\n",
      "  Avg documents: 1.0 per source\n",
      "  Avg processing time: 6077.5ms\n",
      "\n",
      "================================================================================\n",
      "  Recent Sessions\n",
      "================================================================================\n",
      "\n",
      "Session: 2e22ea27-a84a-4ad0-852a-3e2dd85323d0\n",
      "  Date: 2025-04-23 09:57:09\n",
      "  Duration: 6.09 seconds\n",
      "  Documents: 777\n",
      "  Sources: 5 (5 successful, 0 failed)\n",
      "  Success rate: 100.00%\n",
      "\n",
      "Session: c02b6ec7-8e77-4e11-a140-f0c88ebc0d3e\n",
      "  Date: 2025-04-23 09:56:40\n",
      "  Duration: 6.08 seconds\n",
      "  Documents: 777\n",
      "  Sources: 5 (5 successful, 0 failed)\n",
      "  Success rate: 100.00%\n",
      "\n",
      "Session: dd9eb4fc-0575-4fc4-b38c-eac636c43963\n",
      "  Date: 2025-04-22 13:40:48\n",
      "  Duration: 1.76 seconds\n",
      "  Documents: 774\n",
      "  Sources: 5 (2 successful, 3 failed)\n",
      "  Success rate: 40.00%\n",
      "\n",
      "Session: 3c2f6a88-f8b2-47ea-b92b-5faa8d43fd97\n",
      "  Date: 2025-04-22 13:40:33\n",
      "  Duration: 1.70 seconds\n",
      "  Documents: 774\n",
      "  Sources: 5 (2 successful, 3 failed)\n",
      "  Success rate: 40.00%\n",
      "\n",
      "Session: 5a3f7d2a-77ef-4750-b764-c85b05bfee8b\n",
      "  Date: 2025-04-22 13:10:23\n",
      "  Duration: 1.69 seconds\n",
      "  Documents: 774\n",
      "  Sources: 5 (2 successful, 3 failed)\n",
      "  Success rate: 40.00%\n",
      "\n",
      "================================================================================\n",
      "  Detailed Session Report: 2e22ea27-a84a-4ad0-852a-3e2dd85323d0\n",
      "================================================================================\n",
      "Session: 2e22ea27-a84a-4ad0-852a-3e2dd85323d0\n",
      "  Date: 2025-04-23 09:57:09\n",
      "  Duration: 6.09 seconds\n",
      "  Documents: 777\n",
      "  Sources: 5 (5 successful, 0 failed)\n",
      "  Success rate: 100.00%\n",
      "\n",
      "Source Details:\n",
      "\n",
      "✅ /home/user/RAGdoll/tests/test_data/test_txt.txt (.txt)\n",
      "  Documents: 1\n",
      "  Size: 48 B\n",
      "  Processing time: 24ms\n",
      "\n",
      "✅ /home/user/RAGdoll/tests/test_data/test_docx.docx (.docx)\n",
      "  Documents: 1\n",
      "  Size: 319.5 KB\n",
      "  Processing time: 2574ms\n",
      "\n",
      "✅ /home/user/RAGdoll/tests/test_data/test_xlsx.xlsx (.xlsx)\n",
      "  Documents: 1\n",
      "  Size: 28.5 KB\n",
      "  Processing time: 5823ms\n",
      "\n",
      "✅ /home/user/RAGdoll/tests/test_data/test_pdf.pdf (.pdf)\n",
      "  Documents: 773\n",
      "  Size: 2.7 MB\n",
      "  Processing time: 5940ms\n",
      "\n",
      "✅ /home/user/RAGdoll/tests/test_data/test_pptx.pptx (.pptx)\n",
      "  Documents: 1\n",
      "  Size: 212.8 KB\n",
      "  Processing time: 6084ms\n"
     ]
    }
   ],
   "source": [
    "# Notebook-friendly version of the dashboard script\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from ragdoll.metrics.metrics_manager import MetricsManager\n",
    "\n",
    "def print_section(title: str):\n",
    "    \"\"\"Print a section title.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "def print_session_summary(session: Dict[str, Any]):\n",
    "    \"\"\"Print a summary of a session.\"\"\"\n",
    "    start_time = datetime.fromisoformat(session[\"timestamp_start\"])\n",
    "    \n",
    "    print(f\"Session: {session['session_id']}\")\n",
    "    print(f\"  Date: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"  Duration: {session.get('duration_seconds', 0):.2f} seconds\")\n",
    "    print(f\"  Documents: {session['document_count']}\")\n",
    "    print(f\"  Sources: {session['success_count'] + session['failure_count']} \"\n",
    "          f\"({session['success_count']} successful, {session['failure_count']} failed)\")\n",
    "    print(f\"  Success rate: {session.get('success_rate', 0):.2%}\")\n",
    "\n",
    "def format_bytes(bytes_count: int) -> str:\n",
    "    \"\"\"Format bytes as human-readable size.\"\"\"\n",
    "    if bytes_count < 1024:\n",
    "        return f\"{bytes_count} B\"\n",
    "    elif bytes_count < 1024**2:\n",
    "        return f\"{bytes_count / 1024:.1f} KB\"\n",
    "    elif bytes_count < 1024**3:\n",
    "        return f\"{bytes_count / (1024**2):.1f} MB\"\n",
    "    else:\n",
    "        return f\"{bytes_count / (1024**3):.2f} GB\"\n",
    "\n",
    "# Initialize metrics manager with the path to your metrics directory\n",
    "metrics_dir = Path.home() / \".ragdoll\" / \"metrics\"\n",
    "metrics_manager = MetricsManager(metrics_dir=metrics_dir)\n",
    "\n",
    "# Show aggregate metrics and recent sessions\n",
    "print_section(\"RAGdoll Metrics Dashboard\")\n",
    "\n",
    "# Get aggregate metrics for the last 30 days\n",
    "days = 30\n",
    "try:\n",
    "    # Fix the date handling issue by using timedelta\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    # Monkey patch the get_aggregate_metrics method to avoid date issues\n",
    "    def fixed_get_aggregate_metrics(self, days=30):\n",
    "        cutoff_date = datetime.now() - timedelta(days=days)\n",
    "        \n",
    "        aggregate = {\n",
    "            \"total_sessions\": 0,\n",
    "            \"total_documents\": 0,\n",
    "            \"total_sources\": 0,\n",
    "            \"successful_sources\": 0,\n",
    "            \"failed_sources\": 0,\n",
    "            \"avg_success_rate\": 0,\n",
    "            \"avg_documents_per_source\": 0,\n",
    "            \"avg_processing_time_ms\": 0,\n",
    "            \"by_source_type\": {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            json_files = list(self.metrics_dir.glob(\"session_*.json\"))\n",
    "            \n",
    "            # Process each session file\n",
    "            for file_path in json_files:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    session = json.load(f)\n",
    "                \n",
    "                # Skip if older than cutoff\n",
    "                session_date = datetime.fromisoformat(session.get(\"timestamp_start\", \"\"))\n",
    "                if session_date < cutoff_date:\n",
    "                    continue\n",
    "                \n",
    "                # Update aggregate metrics\n",
    "                aggregate[\"total_sessions\"] += 1\n",
    "                aggregate[\"total_documents\"] += session.get(\"document_count\", 0)\n",
    "                aggregate[\"total_sources\"] += session.get(\"success_count\", 0) + session.get(\"failure_count\", 0)\n",
    "                aggregate[\"successful_sources\"] += session.get(\"success_count\", 0)\n",
    "                aggregate[\"failed_sources\"] += session.get(\"failure_count\", 0)\n",
    "                \n",
    "                # Process by source type\n",
    "                for source_key, source_metrics in session.get(\"sources\", {}).items():\n",
    "                    source_type = source_metrics.get(\"source_type\", \"unknown\")\n",
    "                    \n",
    "                    if source_type not in aggregate[\"by_source_type\"]:\n",
    "                        aggregate[\"by_source_type\"][source_type] = {\n",
    "                            \"count\": 0,\n",
    "                            \"success_count\": 0,\n",
    "                            \"document_count\": 0,\n",
    "                            \"total_processing_time_ms\": 0\n",
    "                        }\n",
    "                    \n",
    "                    type_metrics = aggregate[\"by_source_type\"][source_type]\n",
    "                    type_metrics[\"count\"] += 1\n",
    "                    \n",
    "                    if source_metrics.get(\"success\", False):\n",
    "                        type_metrics[\"success_count\"] += 1\n",
    "                    \n",
    "                    type_metrics[\"document_count\"] += source_metrics.get(\"document_count\", 0)\n",
    "                    type_metrics[\"total_processing_time_ms\"] += source_metrics.get(\"processing_time_ms\", 0)\n",
    "            \n",
    "            # Calculate averages\n",
    "            if aggregate[\"total_sources\"] > 0:\n",
    "                aggregate[\"avg_success_rate\"] = aggregate[\"successful_sources\"] / aggregate[\"total_sources\"]\n",
    "                aggregate[\"avg_documents_per_source\"] = aggregate[\"total_documents\"] / aggregate[\"total_sources\"]\n",
    "                \n",
    "                total_time = 0\n",
    "                total_items = 0\n",
    "                for source_type, metrics in aggregate[\"by_source_type\"].items():\n",
    "                    total_time += metrics[\"total_processing_time_ms\"]\n",
    "                    total_items += metrics[\"count\"]\n",
    "                    \n",
    "                    # Calculate source type specific metrics\n",
    "                    if metrics[\"count\"] > 0:\n",
    "                        metrics[\"avg_processing_time_ms\"] = metrics[\"total_processing_time_ms\"] / metrics[\"count\"]\n",
    "                        metrics[\"avg_documents\"] = metrics[\"document_count\"] / metrics[\"count\"]\n",
    "                        metrics[\"success_rate\"] = metrics[\"success_count\"] / metrics[\"count\"]\n",
    "                \n",
    "                if total_items > 0:\n",
    "                    aggregate[\"avg_processing_time_ms\"] = total_time / total_items\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating aggregate metrics: {e}\")\n",
    "            \n",
    "        return aggregate\n",
    "    \n",
    "    # Apply the monkey patch\n",
    "    from types import MethodType\n",
    "    metrics_manager.get_aggregate_metrics = MethodType(fixed_get_aggregate_metrics, metrics_manager)\n",
    "    \n",
    "    aggregate = metrics_manager.get_aggregate_metrics(days=days)\n",
    "    \n",
    "    print(f\"Showing metrics for the past {days} days:\")\n",
    "    print(f\"  Total sessions: {aggregate['total_sessions']}\")\n",
    "    print(f\"  Total documents: {aggregate['total_documents']}\")\n",
    "    print(f\"  Total sources: {aggregate['total_sources']}\")\n",
    "    print(f\"  Success rate: {aggregate['avg_success_rate']:.2%}\")\n",
    "    print(f\"  Avg processing time: {aggregate['avg_processing_time_ms']:.1f}ms per source\")\n",
    "    \n",
    "    # Show metrics by source type\n",
    "    print_section(\"Metrics by Source Type\")\n",
    "    for source_type, metrics in aggregate[\"by_source_type\"].items():\n",
    "        print(f\"\\n{source_type.upper()} Sources:\")\n",
    "        print(f\"  Count: {metrics['count']}\")\n",
    "        print(f\"  Success rate: {metrics.get('success_rate', 0):.2%}\")\n",
    "        print(f\"  Avg documents: {metrics.get('avg_documents', 0):.1f} per source\")\n",
    "        print(f\"  Avg processing time: {metrics.get('avg_processing_time_ms', 0):.1f}ms\")\n",
    "    \n",
    "    # Show recent sessions\n",
    "    recent_sessions = metrics_manager.get_recent_sessions(limit=5)\n",
    "    \n",
    "    print_section(\"Recent Sessions\")\n",
    "    for session in recent_sessions:\n",
    "        print(\"\")\n",
    "        print_session_summary(session)\n",
    "        \n",
    "    # Pick a specific session to view in detail\n",
    "    if recent_sessions:\n",
    "        session_id = recent_sessions[0][\"session_id\"]\n",
    "        print_section(f\"Detailed Session Report: {session_id}\")\n",
    "        \n",
    "        # Get the session data\n",
    "        session_path = Path(metrics_manager.metrics_dir) / f\"session_{session_id}.json\"\n",
    "        with open(session_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            session = json.load(f)\n",
    "        \n",
    "        print_session_summary(session)\n",
    "        \n",
    "        print(\"\\nSource Details:\")\n",
    "        for source_id, source_data in session[\"sources\"].items():\n",
    "            success = \"✅\" if source_data[\"success\"] else \"❌\"\n",
    "            error = f\" - Error: {source_data['error']}\" if source_data[\"error\"] else \"\"\n",
    "            \n",
    "            print(f\"\\n{success} {source_id} ({source_data['source_type']}){error}\")\n",
    "            print(f\"  Documents: {source_data['document_count']}\")\n",
    "            print(f\"  Size: {format_bytes(source_data['bytes'])}\")\n",
    "            print(f\"  Processing time: {source_data['processing_time_ms']}ms\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error running dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f39e8c",
   "metadata": {},
   "source": [
    "### Export to file\n",
    "\n",
    "Export to other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "604f4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Export to CSV\n",
    "def export_sessions_to_csv(metrics_manager, output_path):\n",
    "    sessions = metrics_manager.get_recent_sessions(limit=100)\n",
    "    \n",
    "    with open(output_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['session_id', 'timestamp', 'documents', 'sources', \n",
    "                      'success_rate', 'duration_seconds']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for session in sessions:\n",
    "            writer.writerow({\n",
    "                'session_id': session['session_id'],\n",
    "                'timestamp': session['timestamp_start'],\n",
    "                'documents': session['document_count'],\n",
    "                'sources': session['success_count'] + session['failure_count'],\n",
    "                'success_rate': session['success_rate'],\n",
    "                'duration_seconds': session['duration_seconds']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3c645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
