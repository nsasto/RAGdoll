{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2af900",
   "metadata": {},
   "source": [
    "# Caching & Metrics Playground\n",
    "\n",
    "This notebook demonstrates how DocumentLoaderService can be wired with CacheManager and MetricsManager so that remote content can be cached locally while ingestion sessions are recorded for later analysis. A dummy website loader keeps the demo offline while still exercising the cache/metrics hooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacced30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from ragdoll.cache.cache_manager import CacheManager\n",
    "from ragdoll.ingestion.document_loaders import DocumentLoaderService\n",
    "from ragdoll.metrics.metrics_manager import MetricsManager\n",
    "\n",
    "DATA_DIR = Path(\"../tests/test_data\").resolve()\n",
    "SAMPLE_TXT = DATA_DIR / \"test_txt.txt\"\n",
    "\n",
    "REMOTE_DOC_URL = \"https://example.com/demo-summary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyWebsiteLoader:\n",
    "    run_count = 0\n",
    "\n",
    "    def __init__(self, web_path: str):\n",
    "        DummyWebsiteLoader.run_count += 1\n",
    "        self.web_path = web_path\n",
    "\n",
    "    def load(self):\n",
    "        content = SAMPLE_TXT.read_text(encoding=\"utf-8\")\n",
    "        return [\n",
    "            Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"source\": self.web_path,\n",
    "                    \"loader_run\": DummyWebsiteLoader.run_count,\n",
    "                },\n",
    "            )\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir = Path(\"demo_state/cache_metrics_demo\").resolve()\n",
    "metrics_dir = Path(\"demo_state/metrics_metrics_demo\").resolve()\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cache_manager = CacheManager(cache_dir=str(cache_dir), ttl_seconds=60)\n",
    "metrics_manager = MetricsManager(metrics_dir=str(metrics_dir))\n",
    "loader_service = DocumentLoaderService(\n",
    "    use_cache=True,\n",
    "    collect_metrics=True,\n",
    "    cache_manager=cache_manager,\n",
    "    metrics_manager=metrics_manager,\n",
    "    custom_loaders={\"website\": DummyWebsiteLoader},\n",
    ")\n",
    "\n",
    "loader_service.clear_cache(\"website\", REMOTE_DOC_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ingestion - loader runs and data is cached.\n",
      "Documents loaded: 1\n",
      "Loader run count: 1\n",
      "{'source': 'https://example.com/demo-summary', 'loader_run': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"First ingestion - loader runs and data is cached.\")\n",
    "first_docs = loader_service.ingest_documents([REMOTE_DOC_URL])\n",
    "print(f\"Documents loaded: {len(first_docs)}\")\n",
    "print(\"Loader run count:\", DummyWebsiteLoader.run_count)\n",
    "for doc in first_docs:\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fa9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit: True\n",
      "Cached metadata: {'source': 'https://example.com/demo-summary', 'loader_run': 1}\n"
     ]
    }
   ],
   "source": [
    "cached = cache_manager.get_from_cache(\"website\", REMOTE_DOC_URL)\n",
    "print(\"Cache hit:\", bool(cached))\n",
    "if cached:\n",
    "    print(\"Cached metadata:\", cached[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c995952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second ingestion - should reuse the cached payload.\n",
      "Loader run count (should be unchanged): 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Second ingestion - should reuse the cached payload.\")\n",
    "second_docs = loader_service.ingest_documents([REMOTE_DOC_URL])\n",
    "print(\"Loader run count (should be unchanged):\", DummyWebsiteLoader.run_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache and ingesting again (loader runs once more).\n",
      "Loader run count: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Clearing cache and ingesting again (loader runs once more).\")\n",
    "loader_service.clear_cache(\"website\", REMOTE_DOC_URL)\n",
    "third_docs = loader_service.ingest_documents([REMOTE_DOC_URL])\n",
    "print(\"Loader run count:\", DummyWebsiteLoader.run_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18673f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent ingestion sessions:\n",
      "- f4f7972f-1513-43dd-8f42-8615e5144939 processed 1 docs with success rate 100.0%\n",
      "- aeec1164-092b-4adc-b27a-56e5c7b6acb8 processed 1 docs with success rate 100.0%\n",
      "- 8cb8533d-af88-4f68-ad3e-abd5d2b1c076 processed 1 docs with success rate 100.0%\n",
      "- eefbedb2-69d1-47c8-9036-c7cd32b3edbd processed 1 docs with success rate 100.0%\n",
      "- 893738eb-b97e-403d-91e5-726b30db74a9 processed 1 docs with success rate 100.0%\n",
      "Aggregate metrics (past week):\n",
      "  total_sessions: 9\n",
      "  total_documents: 9\n",
      "  total_sources: 9\n",
      "  successful_sources: 9\n",
      "  failed_sources: 0\n",
      "  avg_success_rate: 1.0\n",
      "  avg_documents_per_source: 1.0\n",
      "  avg_processing_time_ms: 0.6666666666666666\n",
      "  by_source_type: {'website': {'count': 9, 'success_count': 9, 'document_count': 9, 'total_processing_time_ms': 6, 'avg_processing_time_ms': 0.6666666666666666, 'avg_documents': 1.0, 'success_rate': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "recent_sessions = metrics_manager.get_recent_sessions(limit=5)\n",
    "print(\"Recent ingestion sessions:\")\n",
    "for session in recent_sessions:\n",
    "    print(\n",
    "        f\"- {session['session_id']} processed {session['document_count']} docs \"\n",
    "        f\"with success rate {session['success_rate']:.1%}\"\n",
    "    )\n",
    "\n",
    "aggregate = metrics_manager.get_aggregate_metrics(days=7)\n",
    "print(\"Aggregate metrics (past week):\")\n",
    "for key, value in aggregate.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session latency: 0.00s\n",
      "Docs/sec: 286.70 (1 docs total)\n",
      "Success rate: 100.0%\n",
      "Sources processed: 1\n",
      "Source failures: 0\n",
      "Sample source \"https://example.com/demo-summary\": 1 docs, 1 ms, 0 bytes, success=True\n",
      "\\nWeekly aggregate breakdown by source type:\n",
      "- website: avg docs 1.0, success 100.0%, avg latency 1 ms\n",
      "Overall weekly success rate: 100.0%, avg docs/source 1.00\n"
     ]
    }
   ],
   "source": [
    "# Derived metrics make the session information more explicit.\n",
    "extra_session = metrics_manager.get_recent_sessions(limit=1)\n",
    "if extra_session:\n",
    "    session_metrics = extra_session[0]\n",
    "    duration = session_metrics.get(\"duration_seconds\") or 0\n",
    "    document_count = session_metrics.get(\"document_count\", 0)\n",
    "    docs_per_second = document_count / duration if duration else 0\n",
    "    print(f\"Session latency: {duration:.2f}s\")\n",
    "    print(f\"Docs/sec: {docs_per_second:.2f} ({document_count} docs total)\")\n",
    "    print(f\"Success rate: {session_metrics.get(\"success_rate\", 0):.1%}\")\n",
    "    source_metrics = session_metrics.get(\"sources\", {})\n",
    "    print(f\"Sources processed: {len(source_metrics)}\")\n",
    "    failures = sum(1 for metrics in source_metrics.values() if not metrics.get(\"success\"))\n",
    "    print(f\"Source failures: {failures}\")\n",
    "    if source_metrics:\n",
    "        sample_id, sample_metrics = next(iter(source_metrics.items()))\n",
    "        print(\n",
    "            f\"Sample source \\\"{sample_id}\\\": {sample_metrics.get(\"document_count\", 0)} docs, \"\n",
    "            f\"{sample_metrics.get(\"processing_time_ms\", 0):.0f} ms, \"\n",
    "            f\"{sample_metrics.get(\"bytes\", 0)} bytes, success={sample_metrics.get(\"success\")}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No sessions have been recorded yet; run ingestion to capture derived metrics.\")\n",
    "weekly_aggregate = metrics_manager.get_aggregate_metrics(days=7)\n",
    "print(\"\\nWeekly aggregate breakdown by source type:\")\n",
    "for source_type, stats in weekly_aggregate.get(\"by_source_type\", {}).items():\n",
    "    print(\n",
    "        f\"- {source_type}: avg docs {stats.get(\"avg_documents\", 0):.1f}, \"\n",
    "        f\"success {stats.get(\"success_rate\", 0):.1%}, \"\n",
    "        f\"avg latency {stats.get(\"avg_processing_time_ms\", 0):.0f} ms\"\n",
    "    )\n",
    "print(\n",
    "    f\"Overall weekly success rate: {weekly_aggregate.get(\"avg_success_rate\", 0):.1%}, \"\n",
    "    f\"avg docs/source {weekly_aggregate.get(\"avg_documents_per_source\", 0):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d011c",
   "metadata": {},
   "source": [
    "- Run the cells above to observe how the same URL is loaded once, cached, and then read from cache on subsequent runs.\n",
    "- The metrics panel at the end surfaces the session history plus aggregates so you can spot ingestion latency, success, and document counts over time.\n",
    "- The derived metrics cell highlights session latency, throughput, per-source document/error counts, and aggregate breakdowns by source type.\n",
    "- Beyond these examples, consider tracking session latency and throughput, source document/error counts, cache hit/error rates, retry/error counts, quality/cost indicators (duplicate ratio, embedding quality, token spend), and resource usage snapshots so regression signals and cost spikes are easier to spot.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
