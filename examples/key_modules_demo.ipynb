{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c9aadd",
   "metadata": {},
   "source": [
    "# RAGdoll Key Modules Demo\n",
    "\n",
    "Hands-on walkthrough for ingestion, chunking, embeddings, storage layers, and orchestration. Every example relies on the sample assets under `tests/test_data`, so the notebook can run offline.\n",
    "\n",
    "> **Note:** \n",
    "- Set `USE_OPENAI = True` at the top to use real OpenAI embeddings, `False` for fake embeddings.\n",
    "- Cells 7 and 9 call OpenAI's GPT endpoints via `get_llm_caller`. Export `OPENAI_API_KEY` (or add it to `.env`) before running them.\n",
    "- **SSL Certificate Issues**: If you encounter `SSL: CERTIFICATE_VERIFY_FAILED` errors (common in corporate networks), see the SSL workaround cell below to disable verification for development purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21e3cb",
   "metadata": {},
   "source": [
    "## What you'll see\n",
    "\n",
    "1. **Ingestion** – `DocumentLoaderService` from [`docs/ingestion.md`](../docs/ingestion.md).\n",
    "2. **Chunking** – `ragdoll.chunkers` helpers from [`docs/chunking.md`](../docs/chunking.md).\n",
    "3. **Embeddings** – provider factory from [`docs/embeddings.md`](../docs/embeddings.md) controlled by USE_OPENAI flag.\n",
    "4. **Vector stores** – `vector_store_from_config` customization from [`docs/vector_stores.md`](../docs/vector_stores.md).\n",
    "5. **Graph stores** – `get_graph_store` JSON persistence from [`docs/graph_stores.md`](../docs/graph_stores.md).\n",
    "6. **Entity extraction** – `EntityExtractionService` for building knowledge graphs.\n",
    "7. **LLMs** – `get_llm_caller`/`call_llm_sync` bridge described in [`docs/llm_integration.md`](../docs/llm_integration.md) hitting your real OpenAI model.\n",
    "8. **Pipeline** – `IngestionPipeline` snapshot from [`docs/architecture.md`](../docs/architecture.md).\n",
    "9. **Retrieval** – New modular retrieval system with `VectorRetriever`, `GraphRetriever`, and `HybridRetriever` from [`docs/retrieval.md`](../docs/retrieval.md).\n",
    "10. **Advanced Patterns** – Hybrid retrieval modes, graph traversal strategies, and async retrieval.\n",
    "\n",
    "Each cell builds on the previous ones so you can treat this as a scratchpad for experimenting with new loaders or configuration overrides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06129f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from ragdoll import Ragdoll\n",
    "from ragdoll.app_config import bootstrap_app\n",
    "from ragdoll.ingestion import DocumentLoaderService\n",
    "from ragdoll.chunkers import get_text_splitter, split_documents\n",
    "from ragdoll.embeddings import get_embedding_model\n",
    "from ragdoll.vector_stores import vector_store_from_config\n",
    "from ragdoll.config.base_config import VectorStoreConfig\n",
    "from ragdoll.graph_stores import get_graph_store\n",
    "from ragdoll.entity_extraction import EntityExtractionService\n",
    "from ragdoll.entity_extraction.models import Graph, GraphNode, GraphEdge\n",
    "from ragdoll.entity_extraction.graph_persistence import GraphPersistenceService\n",
    "from ragdoll.retrieval import VectorRetriever, GraphRetriever, HybridRetriever\n",
    "from ragdoll.llms import get_llm_caller\n",
    "from ragdoll.llms.callers import call_llm_sync\n",
    "from ragdoll.pipeline import ingest_documents, IngestionPipeline, IngestionOptions\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c20c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_DIR = Path('../tests/test_data').resolve()\n",
    "STATE_DIR = Path('demo_state').resolve()\n",
    "STATE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SAMPLE_TXT = DATA_DIR / 'test_txt.txt'\n",
    "#SAMPLE_TXT = DATA_DIR / '*'\n",
    "\n",
    "# Set to True to use real OpenAI embeddings, False for fake embeddings\n",
    "USE_OPENAI = True\n",
    "\n",
    "app_config = bootstrap_app(\n",
    "    overrides={\n",
    "        'monitor': {'enabled': False, 'collect_metrics': False},\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def normalize_documents(raw_docs):\n",
    "    docs = []\n",
    "    for entry in raw_docs:\n",
    "        if isinstance(entry, Document):\n",
    "            docs.append(entry)\n",
    "        elif isinstance(entry, dict):\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=str(entry.get('page_content', '')),\n",
    "                    metadata=entry.get('metadata', {}) or {},\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            docs.append(Document(page_content=str(entry), metadata={}))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def reset_subdir(name: str) -> Path:\n",
    "    path = STATE_DIR / name\n",
    "    if path.exists():\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "                break\n",
    "            except PermissionError:\n",
    "                time.sleep(0.5)\n",
    "        else:\n",
    "            timestamped = STATE_DIR / f\"{name}_{int(time.time())}\"\n",
    "            timestamped.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Warning: {path} was locked, using {timestamped} instead.\")\n",
    "            return timestamped\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33445758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key len: 164 prefix: sk-proj-Ml-_ suffix: NUDc8A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "k = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Key len:\", len(k), \"prefix:\", k[:12], \"suffix:\", k[-6:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29502297",
   "metadata": {},
   "source": [
    "## 1. Load sample data\n",
    "`DocumentLoaderService` fans out across the loader registry defined in `ragdoll/config/default_config.yaml`. We point it at the lightweight TXT fixture so the demo does not need optional dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53759c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s) from test_txt.txt\n",
      "Metadata sample:\n",
      "{'source': 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_txt.txt'}\n",
      "Preview:\n",
      "Rag graph, or Retrieval-Augmented Generation with graph-based knowledge representation, enhances traditional RAG systems by structuring retrieved information into a dynamic knowledge graph rather than treating it as flat text chunks. At its core, it begins with a user query that triggers a retrieval step from a vector database or search index. Instead of directly feeding retrieved documents into a\n"
     ]
    }
   ],
   "source": [
    "loader = DocumentLoaderService(\n",
    "    app_config=app_config,\n",
    "    use_cache=False,\n",
    "    collect_metrics=False,\n",
    ")\n",
    "\n",
    "raw_documents = loader.ingest_documents([str(SAMPLE_TXT)])\n",
    "documents = normalize_documents(raw_documents)\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s) from {SAMPLE_TXT.name}\")\n",
    "print('Metadata sample:')\n",
    "pprint(documents[0].metadata)\n",
    "print('Preview:')\n",
    "print(documents[0].page_content[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416bedd",
   "metadata": {},
   "source": [
    "## 2. Chunk documents\n",
    "`ragdoll.chunkers.get_text_splitter` mirrors the strategies in [`docs/chunking.md`](../docs/chunking.md). Reusing the splitter instance keeps experiments consistent when you tweak chunk sizes/overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b56c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 20 chunk(s)\n",
      "Chunk 1 metadata: {'source': 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_txt.txt', 'chunk_id': '7623481e_0_v1'}\n",
      "Rag graph, or Retrieval-Augmented Generation with graph-based knowledge representation, enhances traditional RAG systems by structuring retrieved information into a dynamic knowled\n",
      "---\n",
      "Chunk 2 metadata: {'source': 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_txt.txt', 'chunk_id': '7623481e_0_v1'}\n",
      "it as flat text chunks. At its core, it begins with a user query that triggers a retrieval step from a vector database or search index. Instead of directly feeding retrieved docume\n",
      "---\n",
      "Chunk 3 metadata: {'source': 'C:\\\\dev\\\\RAGdoll\\\\tests\\\\test_data\\\\test_txt.txt', 'chunk_id': '7623481e_0_v1'}\n",
      "the system parses these documents to extract entities (such as people, organizations, or concepts) and relationships (like \"works at\" or \"caused by\") using named entity recognition\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "splitter = get_text_splitter(\n",
    "    splitter_type='recursive',\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=40,\n",
    "    app_config=app_config,\n",
    ")\n",
    "chunks = split_documents(documents, text_splitter=splitter)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunk(s)\")\n",
    "for idx, chunk in enumerate(chunks[:3], start=1):\n",
    "    preview = chunk.page_content[:180].replace('\\n', ' ')\n",
    "    print(f\"Chunk {idx} metadata: {chunk.metadata}\")\n",
    "    print(preview)\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf55d4",
   "metadata": {},
   "source": [
    "## 3. Create embeddings\n",
    "`ragdoll.embeddings.get_embedding_model` instantiates providers dynamically. Passing `provider=\"fake\"` gives deterministic vectors without hitting OpenAI/HuggingFace, but the rest of the flow matches production usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7842ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a356222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 embedding vector(s) with dimension 1536\n",
      "First vector slice: [-0.0021977098658680916, 0.01036502793431282, -0.011459833942353725, 0.009982817806303501, -0.004256139509379864, -0.01772419735789299, -0.015832580626010895, -0.014394433237612247]\n"
     ]
    }
   ],
   "source": [
    "embedding_inputs = [chunk.page_content for chunk in chunks[:3]]\n",
    "if not embedding_inputs:\n",
    "    embedding_inputs = [documents[0].page_content]\n",
    "\n",
    "embeddings = (\n",
    "    get_embedding_model() if USE_OPENAI \n",
    "    else get_embedding_model(provider='fake', size=256)\n",
    ")\n",
    "vectors = embeddings.embed_documents(embedding_inputs)\n",
    "\n",
    "print(f\"Generated {len(vectors)} embedding vector(s) with dimension {len(vectors[0])}\")\n",
    "print('First vector slice:', vectors[0][:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c608c",
   "metadata": {},
   "source": [
    "## 4. Build a vector store\n",
    "`vector_store_from_config` consumes a `VectorStoreConfig`, so you can swap FAISS/Chroma/etc. on demand. This cell provisions a Chroma collection under `demo_state` and runs a quick similarity query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b75b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (source=C:\\dev\\RAGdoll\\tests\\test_data\\test_txt.txt) -> it as flat text chunks. At its core, it begins with a user query that triggers a retrieval step from a vector database or search index. Instead of directly feed\n",
      "Result 2 (source=C:\\dev\\RAGdoll\\tests\\test_data\\test_txt.txt) -> Finally, the output includes not just the generated text but optional graph visualizations or citations mapping back to original documents. This traceability im\n"
     ]
    }
   ],
   "source": [
    "core_store_dir = reset_subdir('chroma_core_demo')\n",
    "vector_config = VectorStoreConfig(\n",
    "    enabled=True,\n",
    "    store_type='chroma',\n",
    "    params={\n",
    "        'collection_name': 'ragdoll_core_demo',\n",
    "        'persist_directory': str(core_store_dir),\n",
    "    },\n",
    ")\n",
    "\n",
    "demo_vector_store = vector_store_from_config(\n",
    "    vector_config,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "demo_vector_store.add_documents(chunks)\n",
    "question = 'What content lives in the txt sample?'\n",
    "results = demo_vector_store.similarity_search(question, k=2)\n",
    "for idx, doc in enumerate(results, start=1):\n",
    "    snippet = doc.page_content[:160].replace('\\n', ' ')\n",
    "    print(f\"Result {idx} (source={doc.metadata.get('source')}) -> {snippet}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0f21c",
   "metadata": {},
   "source": [
    "## 5. Run entity extraction + persist a graph\n",
    "`EntityExtractionService` runs spaCy over the chunks and hands everything to `GraphPersistenceService`. We disable re-chunking, dump the output to JSON under `demo_state/`, and render a quick visualization so you can inspect the extracted entities before wiring them into a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42838a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized for entity extraction.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create directories\n",
    "graph_store_dir = reset_subdir('graph_demo')\n",
    "graph_image_path = graph_store_dir / 'graph_demo.png'\n",
    "graph_store_file = graph_store_dir / 'graph.pkl'\n",
    "\n",
    "class ExampleFallbackLLM:\n",
    "    async def call(self, prompt: str) -> str:\n",
    "        return \"Fallback response (no API key for entity extraction)\"\n",
    "    # Initialize LLM\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"OPENAI_API_KEY not set, using fallback LLM for demo.\")\n",
    "    llm_caller = ExampleFallbackLLM()\n",
    "else:\n",
    "    llm_caller = get_llm_caller(app_config=app_config)\n",
    "    if llm_caller is None:\n",
    "        print(\"Unable to initialize LLM, using fallback.\")\n",
    "        llm_caller = ExampleFallbackLLM()\n",
    "    else:\n",
    "        print(\"LLM initialized for entity extraction.\")\n",
    "\n",
    "# Configure ingestion options - use the shared embeddings from earlier\n",
    "options = IngestionOptions(\n",
    "    batch_size=5,\n",
    "    extract_entities=True,\n",
    "    chunking_options={'chunk_size': 1000, 'chunk_overlap': 200},\n",
    "    vector_store_options={\n",
    "        \"store_type\": \"chroma\",\n",
    "        \"params\": {\n",
    "            \"collection_name\": \"graph_demo\",\n",
    "            \"persist_directory\": str(graph_store_dir / \"vector\"),\n",
    "        },\n",
    "    },\n",
    "    graph_store_options={\n",
    "        \"store_type\": \"networkx\",\n",
    "        \"output_file\": str(graph_store_file),\n",
    "    },\n",
    "    llm_caller=llm_caller,\n",
    "    entity_extraction_options={\n",
    "        \"entity_types\": [\"Person\", \"Organization\", \"Location\"],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c87024",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GraphNode\nname\n  Field required [type=missing, input_value={'id': 'spacy-5df3fddc8d1...13:54:07.996906+00:00'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m sources = [\u001b[38;5;28mstr\u001b[39m(SAMPLE_TXT)]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Use ingest_documents which properly handles everything\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m ingest_documents(sources, options=options)\n\u001b[32m      9\u001b[39m stats = result.get(\u001b[33m\"\u001b[39m\u001b[33mstats\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m     10\u001b[39m graph = result.get(\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\pipeline\\__init__.py:497\u001b[39m, in \u001b[36mingest_documents\u001b[39m\u001b[34m(sources, config, options)\u001b[39m\n\u001b[32m    490\u001b[39m     config_manager = app_config.config\n\u001b[32m    492\u001b[39m pipeline = IngestionPipeline(\n\u001b[32m    493\u001b[39m     config_manager=config_manager,\n\u001b[32m    494\u001b[39m     app_config=app_config,\n\u001b[32m    495\u001b[39m     options=options \u001b[38;5;129;01mor\u001b[39;00m IngestionOptions(),\n\u001b[32m    496\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m stats = \u001b[38;5;28;01mawait\u001b[39;00m pipeline.ingest(sources)\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    499\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstats\u001b[39m\u001b[33m\"\u001b[39m: stats,\n\u001b[32m    500\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(pipeline, \u001b[33m\"\u001b[39m\u001b[33mlast_graph\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    501\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgraph_retriever\u001b[39m\u001b[33m\"\u001b[39m: pipeline.get_graph_retriever(),\n\u001b[32m    502\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgraph_store\u001b[39m\u001b[33m\"\u001b[39m: pipeline.get_graph_store(),\n\u001b[32m    503\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\pipeline\\__init__.py:264\u001b[39m, in \u001b[36mIngestionPipeline.ingest\u001b[39m\u001b[34m(self, sources)\u001b[39m\n\u001b[32m    261\u001b[39m             chunk.metadata[\u001b[33m\"\u001b[39m\u001b[33membedding_timestamp\u001b[39m\u001b[33m\"\u001b[39m] = embedding_timestamp\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entity_extractor \u001b[38;5;129;01mand\u001b[39;00m chunks:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._extract_entities(chunks)\n\u001b[32m    266\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mIngestion pipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stats\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\pipeline\\__init__.py:373\u001b[39m, in \u001b[36mIngestionPipeline._extract_entities\u001b[39m\u001b[34m(self, chunks)\u001b[39m\n\u001b[32m    371\u001b[39m                     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mUnable to create graph retriever: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, exc)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     graph = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entity_extractor.extract(chunks)\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m.last_graph = graph\n\u001b[32m    375\u001b[39m     edge_count = \u001b[38;5;28mlen\u001b[39m(graph.edges) \u001b[38;5;28;01mif\u001b[39;00m graph \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\entity_extraction\\entity_extraction_service.py:148\u001b[39m, in \u001b[36mEntityExtractionService.extract\u001b[39m\u001b[34m(self, documents, llm_override)\u001b[39m\n\u001b[32m    146\u001b[39m before_node_count = \u001b[38;5;28mlen\u001b[39m(nodes)\n\u001b[32m    147\u001b[39m before_edge_count = \u001b[38;5;28mlen\u001b[39m(edges)\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m nodes.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_spacy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    149\u001b[39m edges.extend(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_relationship_llm(doc, nodes, llm_runner))\n\u001b[32m    150\u001b[39m logger.info(\n\u001b[32m    151\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEntityExtraction: doc \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m complete (+\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m nodes, +\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m edges, totals: nodes=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, edges=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    152\u001b[39m     idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m     \u001b[38;5;28mlen\u001b[39m(edges),\n\u001b[32m    157\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\RAGdoll\\ragdoll\\entity_extraction\\entity_extraction_service.py:296\u001b[39m, in \u001b[36mEntityExtractionService._run_spacy\u001b[39m\u001b[34m(self, document)\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33membedding_timestamp\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m document.metadata:\n\u001b[32m    294\u001b[39m         properties[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m] = document.metadata[\u001b[33m\"\u001b[39m\u001b[33membedding_timestamp\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     node = \u001b[43mGraphNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspacy-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muuid\u001b[49m\u001b[43m.\u001b[49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhex\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43ment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43ment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Store entity text as label\u001b[39;49;00m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     nodes.append(node)\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\RAGdoll\\.venv\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for GraphNode\nname\n  Field required [type=missing, input_value={'id': 'spacy-5df3fddc8d1...13:54:07.996906+00:00'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "# Run ingestion using ingest_documents helper (cleaner approach)\n",
    "from ragdoll.pipeline import ingest_documents\n",
    "from ragdoll.utils import visualize_graph\n",
    "\n",
    "sources = [str(SAMPLE_TXT)]\n",
    "\n",
    "# Use ingest_documents which properly handles everything\n",
    "result = await ingest_documents(sources, options=options)\n",
    "stats = result.get(\"stats\", {})\n",
    "graph = result.get(\"graph\")\n",
    "graph_store = result.get(\"graph_store\")\n",
    "graph_retriever = result.get(\"graph_retriever\")\n",
    "\n",
    "# Print results\n",
    "print(f\"✅ Ingestion complete!\")\n",
    "print(f\"Documents processed: {stats.get('documents_processed')}\")\n",
    "print(f\"Chunks created: {stats.get('chunks_created')}\")\n",
    "print(f\"Entities extracted: {stats.get('entities_extracted')}\")\n",
    "print(f\"Relationships extracted: {stats.get('relationships_extracted')}\")\n",
    "print(f\"Vector entries added: {stats.get('vector_entries_added')}\")\n",
    "print(f\"Graph entries added: {stats.get('graph_entries_added')}\")\n",
    "\n",
    "if stats.get(\"errors\"):\n",
    "    print(f\"⚠️ Warnings/Errors:\")\n",
    "    for error in stats[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Visualize using the utility function (same as graph_rag_ingestion.py)\n",
    "if graph and hasattr(graph, 'nodes') and graph.nodes:\n",
    "    print(f\"\\nVisualizing graph with {len(graph.nodes)} nodes and {len(graph.edges)} edges...\")\n",
    "    visualize_graph(graph, output_image_path=str(graph_image_path), output_json_path=str(graph_store_dir / \"graph_output.json\"))\n",
    "else:\n",
    "    print('No graph available to visualize.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a297f",
   "metadata": {},
   "source": [
    "## 5b. Alternative: Using IngestionPipeline Directly (OPTIONAL - Keep Commented)\n",
    "\n",
    "**⚠️ Note:** This cell is commented out to avoid interfering with Section 9's graph retrieval demos. \n",
    "\n",
    "The manual pipeline approach creates additional graph stores that can conflict with the `graph_store` variable used in later cells. If you want to test this approach, run it separately or ensure later cells use `manual_graph_store` instead of `graph_store`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238104b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Alternative approach: Create pipeline manually for fine-grained control\n",
    "# from ragdoll.pipeline import IngestionPipeline, IngestionOptions\n",
    "# from ragdoll.vector_stores import vector_store_from_config\n",
    "\n",
    "# ## Setup directories for the manual pipeline demo\n",
    "# manual_graph_dir = reset_subdir('graph_manual_demo')\n",
    "# manual_graph_file = manual_graph_dir / 'graph.pkl'\n",
    "# manual_graph_image = manual_graph_dir / 'manual_graph.png'\n",
    "\n",
    "# ## Create a fresh vector store for this demo\n",
    "# manual_vector_store = vector_store_from_config(\n",
    "#     VectorStoreConfig(\n",
    "#         enabled=True,\n",
    "#         store_type=\"chroma\",\n",
    "#         params={\n",
    "#             \"collection_name\": \"manual_graph_demo\",\n",
    "#             \"persist_directory\": str(manual_graph_dir / \"vector\"),\n",
    "#         },\n",
    "#     ),\n",
    "#     embedding=embeddings,\n",
    "# )\n",
    "\n",
    "# ## Configure options with explicit graph store settings\n",
    "# manual_options = IngestionOptions(\n",
    "#     batch_size=5,\n",
    "#     extract_entities=True,\n",
    "#     chunking_options={'chunk_size': 1000, 'chunk_overlap': 200},\n",
    "#     graph_store_options={\n",
    "#         \"store_type\": \"networkx\",  # This will be passed through now\n",
    "#         \"output_file\": str(manual_graph_file),  # This will be passed through now\n",
    "#     },\n",
    "#     llm_caller=llm_caller,\n",
    "#     entity_extraction_options={\n",
    "#         \"entity_types\": [\"Person\", \"Organization\", \"Location\", \"Event\"],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# ## Create the pipeline with all our custom components\n",
    "# manual_pipeline = IngestionPipeline(\n",
    "#     app_config=app_config,\n",
    "#     content_extraction_service=DocumentLoaderService(\n",
    "#         app_config=app_config,\n",
    "#         use_cache=False,\n",
    "#         collect_metrics=False,\n",
    "#     ),\n",
    "#     embedding_model=embeddings,\n",
    "#     vector_store=manual_vector_store,\n",
    "#     options=manual_options,\n",
    "# )\n",
    "\n",
    "# ## Run ingestion\n",
    "# manual_sources = [str(SAMPLE_TXT)]\n",
    "# manual_stats = await manual_pipeline.ingest(manual_sources)\n",
    "# manual_graph = manual_pipeline.last_graph\n",
    "# manual_graph_store = manual_pipeline.get_graph_store()\n",
    "\n",
    "# # Print results\n",
    "# print(f\"✅ Manual Pipeline Ingestion complete!\")\n",
    "# print(f\"Documents processed: {manual_stats.get('documents_processed')}\")\n",
    "# print(f\"Chunks created: {manual_stats.get('chunks_created')}\")\n",
    "# print(f\"Entities extracted: {manual_stats.get('entities_extracted')}\")\n",
    "# print(f\"Relationships extracted: {manual_stats.get('relationships_extracted')}\")\n",
    "# print(f\"Vector entries added: {manual_stats.get('vector_entries_added')}\")\n",
    "# print(f\"Graph entries added: {manual_stats.get('graph_entries_added')}\")\n",
    "# print(f\"Graph store type: {type(manual_graph_store).__name__ if manual_graph_store else 'None'}\")\n",
    "\n",
    "# ## Visualize the manually created graph\n",
    "# if manual_graph and hasattr(manual_graph, 'nodes') and manual_graph.nodes:\n",
    "#     print(f\"\\nVisualizing manual pipeline graph with {len(manual_graph.nodes)} nodes and {len(manual_graph.edges)} edges...\")\n",
    "#     visualize_graph(\n",
    "#         manual_graph, \n",
    "#         output_image_path=str(manual_graph_image), \n",
    "#         output_json_path=str(manual_graph_dir / \"manual_graph_output.json\")\n",
    "#     )\n",
    "# else:\n",
    "#     print('No graph available from manual pipeline.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2832524",
   "metadata": {},
   "source": [
    "## 6. Query vector + graph context\n",
    "`GraphPersistenceService` reloads the extracted graph into a LangChain retriever so we can compare vector hits against graph nodes for the same question. This mirrors the hybrid pattern we feed into the orchestration demo later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae088e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_persistence = GraphPersistenceService(\n",
    "    output_format='custom_graph_object',\n",
    "    retriever_backend='simple',\n",
    "    retriever_config={'top_k': 3, 'include_edges': True},\n",
    ")\n",
    "\n",
    "_ = graph_persistence.save(graph)\n",
    "graph_retriever = graph_persistence.create_retriever()\n",
    "\n",
    "hybrid_question = 'Which people or organizations are mentioned in the txt sample?'\n",
    "vector_hits = demo_vector_store.similarity_search(hybrid_question, k=2)\n",
    "graph_hits = graph_retriever.get_relevant_documents(hybrid_question)\n",
    "\n",
    "print(f\"Vector store returned {len(vector_hits)} document(s)\")\n",
    "for idx, doc in enumerate(vector_hits, start=1):\n",
    "    snippet = doc.page_content[:200].replace('\\n', ' ')\n",
    "    print(f\"- Vector hit {idx} (source={doc.metadata.get('source')}): {snippet}\")\n",
    "\n",
    "print(f\"Graph retriever returned {len(graph_hits)} node(s)\")\n",
    "for doc in graph_hits:\n",
    "    print(\n",
    "        f\"- Node {doc.metadata.get('node_id')} ({doc.metadata.get('node_type')}): {doc.page_content}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85dd0b0",
   "metadata": {},
   "source": [
    "## 7. Wire up an LLM caller\n",
    "`get_llm_caller` now instantiates the OpenAI chat model defined in `ragdoll/config/default_config.yaml` (defaults to `gpt-4o-mini`). Make sure `OPENAI_API_KEY` is available before running the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    raise EnvironmentError('Set OPENAI_API_KEY before calling the real OpenAI demo cell.')\n",
    "\n",
    "openai_llm_caller = get_llm_caller(app_config=app_config)\n",
    "\n",
    "sample_text = chunks[0].page_content if chunks else documents[0].page_content\n",
    "prompt = (\n",
    "    'Summarize the following text sample in one sentence. Mention what the document is about and highlight any key people, organizations, or actions.'\n",
    "    f\"{sample_text[:2048]}\"\n",
    ")\n",
    "print('Sample excerpt:', sample_text[:360].replace('\\n', ' '))\n",
    "llm_reply = call_llm_sync(openai_llm_caller, prompt)\n",
    "print('OpenAI response:', llm_reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d3b54",
   "metadata": {},
   "source": [
    "## 8. Run the ingestion pipeline (async)\n",
    "`IngestionPipeline` stitches together the loader, chunker, embeddings, vector store, and optional graph/entity stages. We disable entity extraction to keep the run lightweight and await the coroutine directly inside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_store_dir = reset_subdir('chroma_pipeline_demo')\n",
    "pipeline_vector_config = VectorStoreConfig(\n",
    "    enabled=True,\n",
    "    store_type='chroma',\n",
    "    params={\n",
    "        'collection_name': 'ragdoll_pipeline_demo',\n",
    "        'persist_directory': str(pipeline_store_dir),\n",
    "    },\n",
    ")\n",
    "pipeline_vector_store = vector_store_from_config(\n",
    "    pipeline_vector_config,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    app_config=app_config,\n",
    "    content_extraction_service=DocumentLoaderService(\n",
    "        app_config=app_config,\n",
    "        use_cache=False,\n",
    "        collect_metrics=False,\n",
    "    ),\n",
    "    embedding_model=embeddings,\n",
    "    vector_store=pipeline_vector_store,\n",
    "    options=IngestionOptions(\n",
    "        batch_size=2,\n",
    "        extract_entities=False,\n",
    "        skip_graph_store=True,\n",
    "        chunking_options={'chunk_size': 300, 'chunk_overlap': 60, 'splitter_type': 'recursive'},\n",
    "    ),\n",
    ")\n",
    "\n",
    "pipeline_stats = await pipeline.ingest([str(SAMPLE_TXT)])\n",
    "pipeline_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01000105",
   "metadata": {},
   "source": [
    "## 9. Use the new retrieval module\n",
    "The refactored `ragdoll.retrieval` module provides clean separation between vector, graph, and hybrid retrieval strategies. You can use `VectorRetriever`, `GraphRetriever`, or `HybridRetriever` directly with LangChain compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragdoll.retrieval import VectorRetriever, GraphRetriever, HybridRetriever\n",
    "\n",
    "# Setup vector retriever with the demo vector store\n",
    "vector_retriever = VectorRetriever(\n",
    "    vector_store=demo_vector_store,\n",
    "    top_k=3,\n",
    "    search_type=\"similarity\"\n",
    ")\n",
    "\n",
    "# Query about graph RAG concepts\n",
    "query = \"How does graph RAG handle entity extraction and relationships?\"\n",
    "\n",
    "print(\"=== Vector Retrieval ===\")\n",
    "vector_results = vector_retriever.get_relevant_documents(query)\n",
    "for idx, doc in enumerate(vector_results, start=1):\n",
    "    snippet = doc.page_content[:200].replace('\\n', ' ')\n",
    "    print(f\"Result {idx}: {snippet}...\")\n",
    "    print(f\"  Score: {doc.metadata.get('relevance_score', 'N/A')}\\n\")\n",
    "\n",
    "# If we have a graph store from earlier, demonstrate graph retrieval\n",
    "if 'graph_store' in globals() and graph_store is not None:\n",
    "    print(\"\\n=== Graph Retrieval ===\")\n",
    "    graph_retriever = GraphRetriever(\n",
    "        graph_store=graph_store,\n",
    "        top_k=5,\n",
    "        max_hops=2,\n",
    "        traversal_strategy=\"bfs\"\n",
    "    )\n",
    "    \n",
    "    graph_results = graph_retriever.get_relevant_documents(query)\n",
    "    for idx, doc in enumerate(graph_results, start=1):\n",
    "        node_id = doc.metadata.get('node_id', 'unknown')\n",
    "        node_type = doc.metadata.get('node_type', 'unknown')\n",
    "        hop_distance = doc.metadata.get('hop_distance', 0)\n",
    "        print(f\"Node {idx}: {node_type} '{node_id}' (hop distance: {hop_distance})\")\n",
    "        print(f\"  Content: {doc.page_content[:150]}...\\n\")\n",
    "    \n",
    "    # Demonstrate hybrid retrieval combining both\n",
    "    print(\"\\n=== Hybrid Retrieval (Vector + Graph) ===\")\n",
    "    # Create retriever instances first\n",
    "    vector_ret = VectorRetriever(vector_store=demo_vector_store, top_k=3)\n",
    "    graph_ret = GraphRetriever(graph_store=graph_store, top_k=3, max_hops=1)\n",
    "    \n",
    "    hybrid_retriever = HybridRetriever(\n",
    "        vector_retriever=vector_ret,\n",
    "        graph_retriever=graph_ret,\n",
    "        mode=\"concat\"  # Can also be \"rerank\", \"weighted\", or \"expand\"\n",
    "    )\n",
    "    \n",
    "    hybrid_results = hybrid_retriever.get_relevant_documents(query)\n",
    "    print(f\"Retrieved {len(hybrid_results)} total documents from hybrid search\")\n",
    "    for idx, doc in enumerate(hybrid_results, start=1):\n",
    "        source = doc.metadata.get('source', 'unknown')\n",
    "        snippet = doc.page_content[:120].replace('\\n', ' ')\n",
    "        print(f\"{idx}. [{source}] {snippet}...\")\n",
    "else:\n",
    "    print(\"\\n(Graph store not available - run Section 5 to create it)\")\n",
    "\n",
    "# Demonstrate different retrieval strategies\n",
    "print(\"\\n=== MMR Search (Maximal Marginal Relevance) ===\")\n",
    "mmr_retriever = VectorRetriever(\n",
    "    vector_store=demo_vector_store,\n",
    "    top_k=3,\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
    ")\n",
    "mmr_results = mmr_retriever.get_relevant_documents(\"What is multi-hop reasoning in RAG systems?\")\n",
    "for idx, doc in enumerate(mmr_results, start=1):\n",
    "    print(f\"{idx}. {doc.page_content[:150].replace(chr(10), ' ')}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef34a9",
   "metadata": {},
   "source": [
    "## 10. Advanced Retrieval Patterns\n",
    "\n",
    "The new retrieval module supports various advanced patterns:\n",
    "\n",
    "### Hybrid Retrieval Modes\n",
    "- **concat**: Simple concatenation of vector and graph results\n",
    "- **rerank**: Rerank combined results by relevance score\n",
    "- **weighted**: Weighted combination (adjust vector_weight/graph_weight)\n",
    "- **expand**: Use vector results as seeds for graph expansion\n",
    "\n",
    "### Graph Traversal Strategies\n",
    "- **BFS (Breadth-First)**: Explores neighbors level by level (default)\n",
    "- **DFS (Depth-First)**: Follows paths deeply before backtracking\n",
    "\n",
    "### Search Types\n",
    "- **similarity**: Standard vector similarity search\n",
    "- **mmr**: Maximal Marginal Relevance for diverse results\n",
    "- **similarity_score_threshold**: Filter by minimum similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe19226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Weighted hybrid retrieval for balanced results\n",
    "if 'graph_store' in globals() and graph_store is not None:\n",
    "    # Create retriever instances with desired parameters\n",
    "    weighted_vector_ret = VectorRetriever(vector_store=demo_vector_store, top_k=5)\n",
    "    weighted_graph_ret = GraphRetriever(graph_store=graph_store, top_k=5)\n",
    "    \n",
    "    weighted_retriever = HybridRetriever(\n",
    "        vector_retriever=weighted_vector_ret,\n",
    "        graph_retriever=weighted_graph_ret,\n",
    "        mode=\"weighted\",\n",
    "        vector_weight=0.6,  # Favor vector results slightly\n",
    "        graph_weight=0.4\n",
    "    )\n",
    "    \n",
    "    query = \"Explain how graph RAG systems handle iterative refinement\"\n",
    "    weighted_results = weighted_retriever.get_relevant_documents(query)\n",
    "    \n",
    "    print(f\"=== Weighted Hybrid Results (vector=0.6, graph=0.4) ===\")\n",
    "    print(f\"Retrieved {len(weighted_results)} documents\\n\")\n",
    "    \n",
    "    for idx, doc in enumerate(weighted_results[:5], start=1):\n",
    "        score = doc.metadata.get('relevance_score', 0)\n",
    "        source_type = 'graph' if 'node_id' in doc.metadata else 'vector'\n",
    "        snippet = doc.page_content[:150].replace('\\n', ' ')\n",
    "        print(f\"{idx}. [{source_type}] Score: {score:.3f}\")\n",
    "        print(f\"   {snippet}...\\n\")\n",
    "    \n",
    "    # Example: Graph expansion mode - use vector hits to seed graph traversal\n",
    "    expand_vector_ret = VectorRetriever(vector_store=demo_vector_store, top_k=2)\n",
    "    expand_graph_ret = GraphRetriever(graph_store=graph_store, max_hops=2)\n",
    "    \n",
    "    expand_retriever = HybridRetriever(\n",
    "        vector_retriever=expand_vector_ret,\n",
    "        graph_retriever=expand_graph_ret,\n",
    "        mode=\"expand\"\n",
    "    )\n",
    "    \n",
    "    expand_query = \"What are graph neural networks used for in RAG?\"\n",
    "    expand_results = expand_retriever.get_relevant_documents(expand_query)\n",
    "    \n",
    "    print(f\"\\n=== Expand Mode (vector seeds + graph traversal) ===\")\n",
    "    print(f\"Retrieved {len(expand_results)} documents from graph expansion\\n\")\n",
    "    \n",
    "    for idx, doc in enumerate(expand_results[:3], start=1):\n",
    "        if 'node_id' in doc.metadata:\n",
    "            node_id = doc.metadata['node_id']\n",
    "            hop = doc.metadata.get('hop_distance', 0)\n",
    "            print(f\"{idx}. Node: {node_id} (hop: {hop})\")\n",
    "            print(f\"   {doc.page_content[:120]}...\\n\")\n",
    "else:\n",
    "    print(\"Graph store not available. Run Section 5 to enable graph retrieval examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f579542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Async retrieval for concurrent queries\n",
    "import asyncio\n",
    "\n",
    "async def demo_async_retrieval():\n",
    "    \"\"\"Demonstrate async retrieval capabilities.\"\"\"\n",
    "    queries = [\n",
    "        \"What is entity extraction?\",\n",
    "        \"How do graph algorithms help RAG?\",\n",
    "        \"Explain knowledge graph construction\"\n",
    "    ]\n",
    "    \n",
    "    # Create retrievers\n",
    "    vector_ret = VectorRetriever(vector_store=demo_vector_store, top_k=2)\n",
    "    \n",
    "    print(\"=== Async Concurrent Retrieval ===\")\n",
    "    # Retrieve all queries concurrently\n",
    "    results = await asyncio.gather(*[\n",
    "        vector_ret.aget_relevant_documents(q) for q in queries\n",
    "    ])\n",
    "    \n",
    "    for query, docs in zip(queries, results):\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"  Found {len(docs)} documents\")\n",
    "        if docs:\n",
    "            print(f\"  Top result: {docs[0].page_content[:100].replace(chr(10), ' ')}...\")\n",
    "\n",
    "# Run async demo\n",
    "await demo_async_retrieval()\n",
    "\n",
    "# Get retriever statistics\n",
    "print(\"\\n=== Retriever Statistics ===\")\n",
    "vector_stats = vector_retriever.get_stats()\n",
    "print(f\"Vector Retriever: {vector_stats}\")\n",
    "\n",
    "if 'graph_retriever' in globals():\n",
    "    graph_stats = graph_retriever.get_stats()\n",
    "    print(f\"Graph Retriever: {graph_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d84821",
   "metadata": {},
   "source": [
    "## 11. Troubleshooting Graph Retrieval\n",
    "\n",
    "If graph retrieval returns no results, it could be due to:\n",
    "\n",
    "1. **Graph Store Wrapper Issue**: The `GraphStoreWrapper` may not properly expose the graph for retrieval\n",
    "2. **Query Mechanism**: The `GraphRetriever` may need exact node matches rather than semantic search\n",
    "3. **Variable Overwriting**: Running multiple pipeline cells (especially the manual pipeline in Section 5b) may overwrite the `graph_store` variable\n",
    "\n",
    "**Quick Fix**: Make sure you've run Section 5 (entity extraction) and **skip** Section 5b (the commented manual pipeline cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f504a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee7cc785",
   "metadata": {},
   "source": [
    "## 12. Graph Store Diagnostics\n",
    "\n",
    "This diagnostic cell helps troubleshoot graph retrieval issues by inspecting the graph store contents and testing retrieval with simple queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6760d8",
   "metadata": {},
   "source": [
    "## 13. Test Graph Store Query Method\n",
    "\n",
    "Test graph retrieval with specific queries and see the returned entities/relationships in triple format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14. Display Graph as Triples (Working Solution)\n",
    "\n",
    "if \"graph_store\" in globals() and graph_store is not None:\n",
    "    print(\"=== Graph Entities and Relationships as Triples ===\\n\")\n",
    "\n",
    "    # Access the NetworkX graph directly\n",
    "    nx_graph = graph_store.store  # This IS the NetworkX DiGraph\n",
    "\n",
    "    print(f\"Total nodes: {nx_graph.number_of_nodes()}\")\n",
    "    print(f\"Total edges: {nx_graph.number_of_edges()}\\n\")\n",
    "\n",
    "    # Display sample nodes\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SAMPLE ENTITIES (first 10 nodes)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    node_data = list(nx_graph.nodes(data=True))[:10]\n",
    "    for idx, (node_id, attrs) in enumerate(node_data, start=1):\n",
    "        node_type = attrs.get(\"type\", \"UNKNOWN\")\n",
    "        node_label = attrs.get(\"label\", node_id)\n",
    "        print(f\"{idx}. [{node_type}] {node_label}\")\n",
    "        print(f\"   ID: {node_id}\")\n",
    "        if \"properties\" in attrs:\n",
    "            print(f\"   Properties: {attrs['properties']}\")\n",
    "        print()\n",
    "\n",
    "    # Display relationships as triples\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RELATIONSHIPS AS TRIPLES (first 20)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    edge_data = list(nx_graph.edges(data=True))[:20]\n",
    "    for idx, (source, target, attrs) in enumerate(edge_data, start=1):\n",
    "        # Get node labels\n",
    "        source_label = nx_graph.nodes[source].get(\"label\", source)\n",
    "        target_label = nx_graph.nodes[target].get(\"label\", target)\n",
    "\n",
    "        # Get relationship type\n",
    "        rel_type = attrs.get(\"type\", \"RELATED_TO\")\n",
    "\n",
    "        print(f\"{idx}. ({source_label}) --[{rel_type}]--> ({target_label})\")\n",
    "\n",
    "        # Show additional edge properties if any\n",
    "        edge_props = {k: v for k, v in attrs.items() if k not in [\"type\", \"label\"]}\n",
    "        if edge_props:\n",
    "            print(f\"   Properties: {edge_props}\")\n",
    "\n",
    "    # Export to file\n",
    "    triples_file = graph_store_dir / \"triples.txt\"\n",
    "    with open(triples_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "        f.write(\"GRAPH ENTITIES AND RELATIONSHIPS\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Total nodes: {nx_graph.number_of_nodes()}\\n\")\n",
    "        f.write(f\"Total edges: {nx_graph.number_of_edges()}\\n\\n\")\n",
    "\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "        f.write(\"ALL ENTITIES\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        for node_id, attrs in nx_graph.nodes(data=True):\n",
    "            node_type = attrs.get(\"type\", \"UNKNOWN\")\n",
    "            node_label = attrs.get(\"label\", node_id)\n",
    "            f.write(f\"[{node_type}] {node_label}\\n\")\n",
    "            f.write(f\"  ID: {node_id}\\n\")\n",
    "            if \"properties\" in attrs:\n",
    "                f.write(f\"  Properties: {attrs['properties']}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "        f.write(\"ALL RELATIONSHIPS (TRIPLES)\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        for idx, (source, target, attrs) in enumerate(\n",
    "            nx_graph.edges(data=True), start=1\n",
    "        ):\n",
    "            source_label = nx_graph.nodes[source].get(\"label\", source)\n",
    "            target_label = nx_graph.nodes[target].get(\"label\", target)\n",
    "            rel_type = attrs.get(\"type\", \"RELATED_TO\")\n",
    "\n",
    "            f.write(f\"{idx}. ({source_label}) --[{rel_type}]--> ({target_label})\\n\")\n",
    "\n",
    "            edge_props = {k: v for k, v in attrs.items() if k not in [\"type\", \"label\"]}\n",
    "            if edge_props:\n",
    "                f.write(f\"   Properties: {edge_props}\\n\")\n",
    "\n",
    "    print(f\"\\n✅ Full graph exported to: {triples_file}\")\n",
    "\n",
    "    # Show how to query the graph using NetworkX APIs\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HOW TO QUERY THE GRAPH (NetworkX APIs)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\n",
    "        \"\"\"\n",
    "# Get a specific node's data:\n",
    "node_data = nx_graph.nodes['node-id']\n",
    "\n",
    "# Get all neighbors of a node:\n",
    "neighbors = list(nx_graph.neighbors('node-id'))\n",
    "\n",
    "# Get all edges connected to a node:\n",
    "edges = list(nx_graph.edges('node-id'))\n",
    "\n",
    "# Find nodes by type:\n",
    "org_nodes = [n for n, d in nx_graph.nodes(data=True) if d.get('type') == 'ORG']\n",
    "\n",
    "# Find relationships of a specific type:\n",
    "uses_edges = [(u, v) for u, v, d in nx_graph.edges(data=True) if d.get('type') == 'USES']\n",
    "\n",
    "# Get all paths between two nodes:\n",
    "import networkx as nx\n",
    "paths = list(nx.all_simple_paths(nx_graph, source='node1', target='node2', cutoff=3))\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"No graph_store available. Run Section 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 15. Inspect Entity Labels and Content (FIXED - Check Properties)\n",
    "\n",
    "if \"graph_store\" in globals() and graph_store is not None:\n",
    "    print(\"=== Entity Details with Readable Content ===\\n\")\n",
    "\n",
    "    nx_graph = graph_store.store\n",
    "\n",
    "    # Check the raw graph object for better labels\n",
    "    if \"graph\" in globals() and hasattr(graph, \"nodes\"):\n",
    "        print(\"Using raw Graph object - checking properties for entity names...\\n\")\n",
    "\n",
    "        print(\"=\" * 70)\n",
    "        print(\"ENTITIES WITH ACTUAL NAMES (first 30)\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        for idx, node in enumerate(list(graph.nodes)[:30], start=1):\n",
    "            node_id = node.id\n",
    "            node_type = node.type\n",
    "            node_label = getattr(node, \"label\", node_id)\n",
    "\n",
    "            # Get additional properties - THE REAL NAME IS HERE!\n",
    "            props = getattr(node, \"properties\", {})\n",
    "\n",
    "            # Try to find the actual entity name in properties\n",
    "            entity_name = (\n",
    "                props.get(\"name\")\n",
    "                or props.get(\"entity_name\")\n",
    "                or props.get(\"text\")\n",
    "                or node_label\n",
    "            )\n",
    "\n",
    "            print(f\"{idx}. [{node_type}] {entity_name}\")\n",
    "            print(f\"   ID: {node_id}\")\n",
    "\n",
    "            # Show ALL properties to find where the real name is\n",
    "            if props:\n",
    "                print(f\"   Properties:\")\n",
    "                for key, value in props.items():\n",
    "                    value_str = str(value)[:100]\n",
    "                    print(f\"     {key}: {value_str}\")\n",
    "            print()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RELATIONSHIPS WITH ACTUAL NAMES (first 30)\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        for idx, edge in enumerate(list(graph.edges)[:30], start=1):\n",
    "            # Get source and target nodes\n",
    "            source_node = next((n for n in graph.nodes if n.id == edge.source), None)\n",
    "            target_node = next((n for n in graph.nodes if n.id == edge.target), None)\n",
    "\n",
    "            # Get actual names from properties\n",
    "            source_props = getattr(source_node, \"properties\", {}) if source_node else {}\n",
    "            target_props = getattr(target_node, \"properties\", {}) if target_node else {}\n",
    "\n",
    "            source_name = (\n",
    "                source_props.get(\"name\")\n",
    "                or source_props.get(\"entity_name\")\n",
    "                or source_props.get(\"text\")\n",
    "                or edge.source\n",
    "            )\n",
    "            target_name = (\n",
    "                target_props.get(\"name\")\n",
    "                or target_props.get(\"entity_name\")\n",
    "                or target_props.get(\"text\")\n",
    "                or edge.target\n",
    "            )\n",
    "\n",
    "            rel_type = edge.type\n",
    "\n",
    "            print(f\"{idx}. ({source_name}) --[{rel_type}]--> ({target_name})\")\n",
    "\n",
    "            # Show edge properties if any\n",
    "            if hasattr(edge, \"properties\") and edge.properties:\n",
    "                print(f\"   Edge properties:\")\n",
    "                for key, value in list(edge.properties.items())[:3]:\n",
    "                    value_str = str(value)[:80]\n",
    "                    print(f\"     {key}: {value_str}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"⚠️ Raw graph object not available.\")\n",
    "        print(\"The 'graph' variable from Section 5 is needed.\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"No graph_store available. Run Section 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c53e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 16. Debug Entity Properties\n",
    "\n",
    "if \"graph\" in globals() and hasattr(graph, \"nodes\"):\n",
    "    print(\"=== Debugging First 5 Nodes Properties ===\\n\")\n",
    "\n",
    "    for idx, node in enumerate(list(graph.nodes)[:5], start=1):\n",
    "        print(f\"{idx}. Node ID: {node.id}\")\n",
    "        print(f\"   Type: {node.type}\")\n",
    "        print(f\"   Label: {getattr(node, 'label', 'NO LABEL')}\")\n",
    "\n",
    "        props = getattr(node, \"properties\", {})\n",
    "        print(f\"   Properties keys: {list(props.keys())}\")\n",
    "        print(f\"   Properties: {props}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
